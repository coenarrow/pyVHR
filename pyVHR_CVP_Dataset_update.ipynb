{"cells":[{"cell_type":"markdown","metadata":{"id":"RndCVqh915_g"},"source":["---\n","# **PyVHR using the CVP Dataset**\n","---"]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFP37oIXuKQN"},"outputs":[],"source":["# -- MAIN IMPORT\n","\n","import pyVHR as vhr\n","from pyVHR.BVP import *\n","from pyVHR.utils.errors import *\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","from tqdm import tqdm\n","\n","# Plotting: set 'colab' for Google Colaboratory, 'notebook' otherwise\n","vhr.plot.VisualizeParams.renderer = 'notebook'"]},{"cell_type":"markdown","metadata":{},"source":["# Function Definitions"]},{"cell_type":"markdown","metadata":{"id":"4cvCF5ktaWIH"},"source":["## Dataframe Functions"]},{"cell_type":"markdown","metadata":{},"source":["### Create Instance DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_instance_dataframe(results_path, base_path):\n","    \"\"\"\n","    Create or load a DataFrame with instance-related information.\n","\n","    Parameters:\n","        results_path (str): The path to save the DataFrame.\n","        base_path (str): The base path containing all video directories.\n","        \n","    Returns:\n","        pd.DataFrame: DataFrame containing instance-related information.\n","    \"\"\"\n","\n","    # Define the JSON filename for DataFrame storage\n","    filename = os.path.join(results_path, \"instance_info.json\")\n","\n","    # Columns for the DataFrame\n","    columns = [ \"INSTANCE\",\n","                \"DATAPATH\", \n","                \"K1_PATH\", \n","                \"K2_PATH\", \n","                \"K1_PROCESSED\", \n","                \"K2_PROCESSED\", \n","                \"GT_PROCESSED\", \n","                \"K1_SKIN_RECTANGLE_COORDS\",\n","                \"K1_PIXEL_THRESHOLD\",\n","                \"K1_SKIN_RECTANGLE_MEAN_RGB\",\n","                \"K2_SKIN_RECTANGLE_COORDS\",\n","                \"K2_PIXEL_THRESHOLD\",\n","                \"K2_SKIN_RECTANGLE_MEAN_RGB\",\n","                \"K1_PATCH_IDS\",\n","                \"K2_PATCH_IDS\"]\n","\n","    if os.path.exists(filename):\n","        # Load DataFrame if already exists\n","        df = pd.read_json(filename)\n","        print(f\"DataFrame loaded from {filename}\")\n","    else:\n","        # Initialize DataFrame with pre-defined columns\n","        df = pd.DataFrame(columns=columns)\n","\n","        # A list to store unique instances\n","        unique_instances = []\n","\n","        # List all directories in the base path\n","        all_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n","\n","        for dir_name in all_dirs:\n","            instance, camera = dir_name.split(\"_\")\n","            instance = int(instance)  # Convert to integer\n","            \n","            if instance not in unique_instances:\n","                unique_instances.append(instance)\n","                \n","                # Prepare a new DataFrame row\n","                new_row = pd.DataFrame([{\n","                    'INSTANCE': instance, \n","                    'DATAPATH': None,\n","                    'K1_PATH': None,\n","                    'K2_PATH': None,\n","                    'K1_SKIN_RECTANGLE_COORDS': (-1,-1,-1,-1),\n","                    'K1_SKIN_RECTANGLE_MEAN_RGB': [-1,-1,-1],\n","                    'K1_PIXEL_THRESHOLD': -1,\n","                    'K2_SKIN_RECTANGLE_COORDS': (-1,-1,-1,-1),\n","                    'K2_SKIN_RECTANGLE_MEAN_RGB': [-1,-1,-1],\n","                    'K2_PIXEL_THRESHOLD': -1,\n","                    'K1_PATCH_NUMBERS': [],\n","                    'K2_PATCH_NUMBERS': [],\n","                }], columns=columns)\n","                \n","                # Append the new row to DataFrame using concat\n","                df = pd.concat([df, new_row], ignore_index=True)\n","\n","            # Populate K1_PATH and K2_PATH fields\n","            shortened_path = os.path.join(base_path, dir_name) + \"\\\\\"\n","            if camera == 'K1':\n","                k1_path = shortened_path + \"K1_Cropped_Colour.mkv\"\n","                # Check if K1 file exists\n","                if os.path.exists(k1_path):\n","                    df.loc[df['INSTANCE'] == instance, 'K1_PATH'] = k1_path\n","                    df.loc[df['INSTANCE'] == instance, 'DATAPATH'] = shortened_path + \"data.csv\"\n","                else:\n","                    df.loc[df['INSTANCE'] == instance, 'K1_PATH'] = None\n","\n","            elif camera == 'K2':\n","                k2_path = shortened_path + \"K2_Cropped_Colour.mkv\"                \n","                # Check if K2 file exists\n","                if os.path.exists(k2_path):\n","                    df.loc[df['INSTANCE'] == instance, 'K2_PATH'] = k2_path\n","                    df.loc[df['INSTANCE'] == instance, 'DATAPATH'] = shortened_path + \"data.csv\"\n","                else:\n","                    df.loc[df['INSTANCE'] == instance, 'K2_PATH'] = None\n","\n","        # Sort DataFrame and reset index\n","        df.sort_values('INSTANCE', inplace=True)\n","        df.reset_index(drop=True, inplace=True)\n","\n","        # Save DataFrame to JSON file\n","        df.to_json(filename)\n","\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["### Create Groundtruth Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_groundtruth_dataframe(instance_df, results_path):\n","    \"\"\"\n","    Create a DataFrame named groundtruth_df, drawing the INSTANCE column from instance_df,\n","    and saves it as a JSON file.\n","\n","    Parameters:\n","        instance_df (pd.DataFrame): The DataFrame containing instance-related information.\n","        results_path (str): The path to save the groundtruth_df as a JSON file.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame containing groundtruth-related information.\n","    \"\"\"\n","    \n","    # Define the JSON filename for DataFrame storage\n","    filename = os.path.join(results_path, \"groundtruth.json\")\n","    \n","    if os.path.exists(filename):\n","        # Load DataFrame if already exists\n","        groundtruth_df = pd.read_json(filename)\n","        print(f\"DataFrame loaded from {filename}\")\n","    else:\n","        # Initialize DataFrame with data types and initial values\n","        columns = [\"INSTANCE\", \"LENGTH\", \"SAMPLE_RATE\", \"ECG\", \"ECG_TIMES\", \n","                   \"ECG_BPM\", \"ABP\", \"ABP_TIMES\", \"ABP_BPM\", \"CVP\", \n","                   \"CVP_TIMES\", \"CVP_BPM\"]\n","\n","        initial_values = {\n","            \"INSTANCE\": [],\n","            \"LENGTH\": [],\n","            \"SAMPLE_RATE\": [],\n","            \"ECG\": [],\n","            \"ECG_TIMES\": [],\n","            \"ECG_BPM\": [],\n","            \"ABP\": [],\n","            \"ABP_TIMES\": [],\n","            \"ABP_BPM\": [],\n","            \"CVP\": [],\n","            \"CVP_TIMES\": [],\n","            \"CVP_BPM\": []\n","        }\n","        \n","        groundtruth_df = pd.DataFrame(initial_values)\n","        \n","        # Populate the INSTANCE column from instance_df\n","        groundtruth_df['INSTANCE'] = instance_df['INSTANCE'].astype(int).copy()\n","        \n","        # Fill the rest of the columns with default values\n","        for column in [\"LENGTH\"]:\n","            groundtruth_df[column] = -1  # Default value for int\n","        for column in [\"SAMPLE_RATE\"]:\n","            groundtruth_df[column] = -1.0  # Default value for float\n","        for column in [\"ECG\", \"ECG_TIMES\", \"ECG_BPM\", \"ABP\", \"ABP_TIMES\", \"ABP_BPM\", \"CVP\", \"CVP_TIMES\", \"CVP_BPM\"]:\n","            groundtruth_df[column] = groundtruth_df[column].apply(lambda x: [])  # Default value for lists\n","\n","        # Save DataFrame to JSON file\n","        groundtruth_df.to_json(filename)\n","        print(f\"DataFrame saved to {filename}\")\n","\n","    return groundtruth_df\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create Holistic Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_holistic_dataframes(methods, results_path):\n","    \"\"\"\n","    Create a DataFrame for each method in the 'methods' list and save it as a JSON file.\n","\n","    Parameters:\n","        methods (list): List of method names.\n","        results_path (str): The path to save the DataFrames as JSON files.\n","    \"\"\"\n","\n","    # Define the common columns for all DataFrames\n","    common_columns = [\"INSTANCE\", \"TIMES\", \"GT\"]\n","\n","    # Define metrics for raw and segmented types\n","    raw_metrics = [\"BPM_RAW\", \"RMSE_RAW\", \"MAE_RAW\", \"PCC_RAW\", \"CCC_RAW\", \"SNR_RAW\"]\n","    segmented_metrics = [\"BPM_SEGMENTED\", \"RMSE_SEGMENTED\", \"MAE_SEGMENTED\", \"PCC_SEGMENTED\", \"CCC_SEGMENTED\", \"SNR_SEGMENTED\"]\n","\n","    # Create K1 and K2 metrics by prefixing the raw and segmented metrics\n","    k1_metrics = [f\"K1_{metric}\" for metric in raw_metrics + segmented_metrics]\n","    k2_metrics = [f\"K2_{metric}\" for metric in raw_metrics + segmented_metrics]\n","\n","    # Combine all columns\n","    all_columns = common_columns + k1_metrics + k2_metrics\n","\n","    # Create a DataFrame for each method and save it\n","    for method in methods:\n","        # Create an empty DataFrame\n","        df_name = f\"holistic_{method}\"\n","        df = pd.DataFrame(columns=all_columns).astype('object')\n","\n","        # Define JSON filename for storing the DataFrame\n","        filename = os.path.join(results_path, f\"{df_name}.json\")\n","\n","        # Save DataFrame to JSON file\n","        df.to_json(filename)"]},{"cell_type":"markdown","metadata":{},"source":["### Create Patch Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_patch_dataframes(methods, results_path):\n","    \"\"\"\n","    Create a DataFrame for each method in the 'methods' list using the 'patch' prefix\n","    and save it as a JSON file.\n","\n","    Parameters:\n","        methods (list): List of method names.\n","        results_path (str): The path to save the DataFrames as JSON files.\n","    \"\"\"\n","\n","    # Define the common columns for all DataFrames\n","    common_columns = [\"INSTANCE\", \"TIMES\",\"GT\"]\n","    metrics = [\"BPM\", \"RMSE\", \"MAE\", \"PCC\", \"CCC\", \"SNR\"]\n","\n","    # Generate columns for K1 and K2 with MED and PSD\n","    k1_med_columns = [f\"K1_MED_{metric}\" for metric in metrics]\n","    k1_psd_columns = [f\"K1_PSD_{metric}\" for metric in metrics]\n","    \n","    k2_med_columns = [f\"K2_MED_{metric}\" for metric in metrics]\n","    k2_psd_columns = [f\"K2_PSD_{metric}\" for metric in metrics]\n","\n","    # Combine all columns\n","    all_columns = common_columns + k1_med_columns + k1_psd_columns + k2_med_columns + k2_psd_columns\n","\n","    # Create a DataFrame for each method and save it\n","    for method in methods:\n","        # Create an empty DataFrame\n","        df_name = f\"patch_{method}\"\n","        df = pd.DataFrame(columns=all_columns).astype('object')\n","\n","        # Define JSON filename for storing the DataFrame\n","        filename = os.path.join(results_path, f\"{df_name}.json\")\n","\n","        # Save DataFrame to JSON file\n","        df.to_json(filename)"]},{"cell_type":"markdown","metadata":{},"source":["### Create Deep Holistic Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_deep_holistic_dataframes(methods, results_path):\n","    \"\"\"\n","    Create a DataFrame for each method in the 'methods' list using the 'deep_patch' prefix\n","    and save it as a JSON file.\n","\n","    Parameters:\n","        methods (list): List of method names.\n","        results_path (str): The path to save the DataFrames as JSON files.\n","    \"\"\"\n","\n","    # Define the common columns for all DataFrames\n","    common_columns = [\"INSTANCE\", \"TIMES\", \"GT\"]\n","\n","    # Define metrics for raw and segmented types\n","    raw_metrics = [\"BPM_RAW\", \"RMSE_RAW\", \"MAE_RAW\", \"PCC_RAW\", \"CCC_RAW\", \"SNR_RAW\"]\n","    segmented_metrics = [\"BPM_SEGMENTED\", \"RMSE_SEGMENTED\", \"MAE_SEGMENTED\", \"PCC_SEGMENTED\", \"CCC_SEGMENTED\", \"SNR_SEGMENTED\"]\n","\n","    # Create K1 and K2 metrics by prefixing the raw and segmented metrics\n","    k1_metrics = [f\"K1_{metric}\" for metric in raw_metrics + segmented_metrics]\n","    k2_metrics = [f\"K2_{metric}\" for metric in raw_metrics + segmented_metrics]\n","\n","    # Combine all columns\n","    all_columns = common_columns + k1_metrics + k2_metrics\n","\n","    # Create a DataFrame for each method and save it\n","    for method in methods:\n","        # Create an empty DataFrame\n","        df_name = f\"deep_holistic_{method}\"\n","        df = pd.DataFrame(columns=all_columns).astype('object')\n","\n","        # Define JSON filename for storing the DataFrame\n","        filename = os.path.join(results_path, f\"{df_name}.json\")\n","\n","        # Save DataFrame to JSON file\n","        df.to_json(filename)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create Deep Patch Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_deep_patch_dataframes(methods, results_path):\n","    \"\"\"\n","    Create a DataFrame for each method in the 'methods' list using the 'deep_holistic' prefix\n","    and save it as a JSON file. This version of the function also accounts for MED and PSD estimations\n","    for both RAW and SEGMENTED data types.\n","\n","    Parameters:\n","        methods (list): List of method names.\n","        results_path (str): The path to save the DataFrames as JSON files.\n","    \"\"\"\n","\n","    # Define the common columns for all DataFrames\n","    common_columns = [\"INSTANCE\", \"TIMES\", \"GT\"]\n","    metrics = [\"BPM\", \"RMSE\", \"MAE\", \"PCC\", \"CCC\", \"SNR\"]\n","    \n","    # Create estimation types and data types\n","    estimation_types = [\"MED\", \"PSD\"]\n","    data_types = [\"RAW\", \"SEGMENTED\"]\n","\n","    # Create columns for K1 and K2 with MED, PSD, RAW, and SEGMENTED\n","    k1_columns = [f\"K1_{est}_{dtype}_{metric}\" for est in estimation_types for dtype in data_types for metric in metrics]\n","    k2_columns = [f\"K2_{est}_{dtype}_{metric}\" for est in estimation_types for dtype in data_types for metric in metrics]\n","\n","    # Combine all columns\n","    all_columns = common_columns + k1_columns + k2_columns\n","\n","    # Create a DataFrame for each method and save it\n","    for method in methods:\n","        # Create an empty DataFrame\n","        df_name = f\"deep_patch_{method}\"\n","        df = pd.DataFrame(columns=all_columns).astype('object')\n","\n","        # Define JSON filename for storing the DataFrame\n","        filename = os.path.join(results_path, f\"{df_name}.json\")\n","\n","        # Save DataFrame to JSON file\n","        df.to_json(filename)"]},{"cell_type":"markdown","metadata":{},"source":["## Groundtruth Functions"]},{"cell_type":"markdown","metadata":{},"source":["### Process Groundtruth"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_ground_truth_data(instance_df, groundtruth_df, results_path, instance, dataset, window_info=[8, 1]):\n","    \"\"\"\n","    Read the ground truth data for ECG, ABP, and CVP signals.\n","    \n","    Parameters:\n","    - instance_df (pd.DataFrame): DataFrame containing the instance paths.\n","    - groundtruth_df (pd.DataFrame): DataFrame to store the BPM and time data.\n","    - instance (str): The instance identifier to locate the row in the DataFrame.\n","    - dataset: An object containing methods for reading signal files.\n","    - window_info (list): [window size, step] for BPM calculation.\n","    \n","    Returns:\n","    - pd.DataFrame: DataFrame with updated BPM and time data.\n","    \"\"\"\n","\n","    instance_filename = os.path.join(results_path, \"instance_info.json\")\n","    groundtruth_filename = os.path.join(results_path, \"groundtruth.json\")\n","    \n","    # Get the index of the instance\n","    index = instance_df[instance_df['INSTANCE'] == int(instance)].index[0]\n","        \n","    if groundtruth_df.at[index, 'LENGTH'] != -1:\n","        print(f\"Instance has already been processed. Skipping.\")\n","        return instance_df, groundtruth_df\n","\n","    try:\n","        sigFileName = instance_df.loc[instance_df['INSTANCE'] == int(instance), 'DATAPATH'].values[0]\n","    except Exception as e:\n","        print(f\"Error in locating DATAPATH: {e}\")\n","        sys.exit(1)\n","\n","    wsize = window_info[0]\n","\n","    def read_signal(signal_type):\n","        try:\n","            sigGT = dataset.readSigfile(sigFileName, signalGT=signal_type)\n","            \n","            # Get the raw signal\n","            raw_signal = sigGT.data\n","\n","            # Get the BPM and time data\n","            bpmGT, timesGT = sigGT.getBPM(wsize)\n","            \n","            idx = groundtruth_df[groundtruth_df['INSTANCE'] == int(instance)].index[0]\n","            \n","            groundtruth_df.at[idx, signal_type] = raw_signal\n","            groundtruth_df.at[idx, f\"{signal_type}_TIMES\"] = timesGT\n","            groundtruth_df.at[idx, f\"{signal_type}_BPM\"] = bpmGT\n","            groundtruth_df.at[idx, \"LENGTH\"] = len(raw_signal[0])\n","            groundtruth_df.at[idx, \"SAMPLE_RATE\"] = dataset.SIG_SampleRate\n","            return groundtruth_df\n","            \n","        except Exception as e:\n","            return groundtruth_df\n","\n","    # Reading ECG, ABP, and CVP signals\n","    for signal_type in [\"ECG\", \"ABP\", \"CVP\"]:\n","        groundtruth_df = read_signal(signal_type)\n","\n","    instance_df.to_json(instance_filename)\n","    groundtruth_df.to_json(groundtruth_filename)\n","\n","    return instance_df, groundtruth_df\n"]},{"cell_type":"markdown","metadata":{},"source":["### Populate Groundtruth Dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def populate_groundtruth_df(instance_df, results_path, dataset, window_info=[8, 1]):\n","\n","    # Populate the ground truth dataframe\n","    groundtruth_df = create_groundtruth_dataframe(instance_df, results_path)\n","    instances = instance_df['INSTANCE'].to_list()\n","    for instance in tqdm(instances,desc=\"Processing instances\"):\n","        try:\n","            instance_df, groundtruth_df = read_ground_truth_data(instance_df, groundtruth_df, results_path, instance, dataset, window_info)\n","        except Exception as e:\n","            continue\n","\n","    return instance_df, groundtruth_df"]},{"cell_type":"markdown","metadata":{},"source":["## Initialise sig_extractor Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def initialize_sig_extractor(seconds=0,patch_info = [40,0]):\n","    patch_size = patch_info[0]\n","    overlap = patch_info[1]\n","    sig_extractor = vhr.extraction.SignalProcessing()\n","    sig_extractor.set_visualize_skin_and_landmarks( visualize_skin=True,\n","                                                    visualize_landmarks=True, \n","                                                    visualize_landmarks_number=False, \n","                                                    visualize_patch=True)\n","    sig_extractor.choose_cuda_device(0)\n","    sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU')) # Set the skin extractor\n","    sig_extractor.set_square_patches_side(patch_info[0])\n","    sig_extractor.set_overlap(overlap)\n","    sig_extractor.thickness = 1\n","    sig_extractor.font_size = 0.3\n","    return sig_extractor"]},{"cell_type":"markdown","metadata":{},"source":["## Patch Processing Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def add_fixed_patch_info(fixed_patches,patch_ids,patch_bvps,patch_bpmES,timesES):\n","    for fixed_patch in fixed_patches:\n","        for window in range(len(patch_ids)):\n","            # loop through each patch, check if it's the one we're after, and append if it is, including the \n","            for patch in range(len(patch_ids[window])):\n","                if patch_ids[window][patch] == fixed_patch.ID:\n","                    fixed_patch.times.append(timesES[window])\n","                    fixed_patch.bvps.append(np.array([patch_bvps[window][patch]]))\n","                    fixed_patch.bpms.append(np.array(patch_bpmES[window][patch]))\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_snrs(fixed_patches,gt_bpms,fps):\n","    for fixed_patch in fixed_patches:\n","        if len(fixed_patch.times) > 0:\n","            fixed_patch.snr = []\n","            for i, bvp in enumerate(fixed_patch.bvps):\n","                fixed_patch.snr.append(get_SNR([bvp],fps,gt_bpms,[fixed_patch.times[i]]))\n","            fixed_patch.snr = np.array(fixed_patch.snr)\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_errors(fixed_patches,gt_times,gt_bpms):\n","    for fixed_patch in fixed_patches:\n","        if len(fixed_patch.times) > 0:\n","            temp_bpms = np.expand_dims(np.array(fixed_patch.bpms),axis=0)\n","            fixed_patch.rmse = RMSEerror(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","            fixed_patch.mae = MAEerror(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","            fixed_patch.max = MAXError(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_metrics(fixed_patches,gt_times,gt_bpms,fps):\n","    try:\n","        fixed_patches = update_patch_snrs(fixed_patches,gt_bpms,fps)\n","    except Exception as e:\n","        print(f\"Error in calculating SNR: {e}\")\n","    try:\n","        fixed_patches = update_patch_errors(fixed_patches,gt_times,gt_bpms)\n","    except Exception as e:\n","        print(f\"Error in calculating errors: {e}\")\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_patch_dataframe(fixed_patches):    \n","    patch_data = []\n","    for fixed_patch in fixed_patches:\n","        patch_data.append([fixed_patch.ID,\n","                        fixed_patch.x_min,\n","                        fixed_patch.x_max,\n","                        fixed_patch.y_min,\n","                        fixed_patch.y_max,\n","                        np.array(fixed_patch.times),\n","                        np.array(fixed_patch.bvps),\n","                        np.array(fixed_patch.bpms),\n","                        fixed_patch.rmse,\n","                        fixed_patch.mae,\n","                        fixed_patch.max,\n","                        np.array(fixed_patch.snr)])\n","    df = pd.DataFrame(patch_data,columns = [\"ID\",\"x_min\",\"x_max\",\"y_min\",\"y_max\",\"times\",\"bvps\",\"bpms\",\"RMSE\",\"MAE\",\"MAX\",\"SNRs\"])\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Skin Segmentation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_skin_segmentation_info(instance_df,results_path,skin_threshold=30):\n","\n","    # Define the list of the instances\n","    instance_filename = os.path.join(results_path, \"instance_info.json\")\n","\n","    # Define the list of the instances\n","    instances = instance_df['INSTANCE'].to_list()\n","\n","    # Set up the sig_extractor\n","    sig_extractor = vhr.extraction.SignalProcessing()\n","    sig_extractor.choose_cuda_device(0)\n","    sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU')) # Set the skin extractor\n","\n","\n","    # Loop through all the instances, open the k1 and k2 video (if they exist)\n","    # get the rectangle coordinates and the mean RGB values, add them to the \n","    # instance_df dataframe\n","    for instance in tqdm(instances,desc=\"Processing instances\"):\n","        # Define the paths for saving the frames\n","        frames_path = os.path.join(results_path, \"figures\", str(instance))\n","        k1_display_frame_path = os.path.join(frames_path, \"K1_display_frames.png\")\n","        k2_display_frame_path = os.path.join(frames_path, \"K2_display_frames.png\")\n","        k1_skin_frame_path = os.path.join(frames_path, \"K1_skin_frames.png\")\n","        k2_skin_frame_path = os.path.join(frames_path, \"K2_skin_frames.png\")\n","\n","        # Get the index of the instance\n","        index_to_update = instance_df[instance_df['INSTANCE'] == int(instance)].index[0]\n","\n","        # Process the K1 video if we can\n","        if instance_df.at[index_to_update, 'K1_SKIN_RECTANGLE_COORDS'] == [-1, -1, -1, -1]:\n","            # Check if the K1 video exists\n","            if instance_df.loc[instance_df['INSTANCE'] == int(instance), 'K1_PATH'].values[0] is None:\n","                continue\n","            else:\n","                # Reset the sig_extractor\n","                sig_extractor.skin_extractor.mean_rgb = None\n","                sig_extractor.skin_extractor.rect = None\n","                sig_extractor.display_frame = None\n","                sig_extractor.skin_frame = None\n","                # Get the video path for the K1\n","                videoFilename = instance_df.loc[instance_df['INSTANCE'] == int(instance), 'K1_PATH'].values[0]\n","                # Get the values\n","                hol_sig = sig_extractor.extract_holistic_rectangle(videoFilename,skin_threshold)\n","                # Add the values to the dataframe\n","                instance_df.at[index_to_update, 'K1_SKIN_RECTANGLE_COORDS'] = tuple(sig_extractor.skin_extractor.rect)\n","                instance_df.at[index_to_update, 'K1_SKIN_RECTANGLE_MEAN_RGB'] = sig_extractor.skin_extractor.mean_rgb.tolist()\n","                instance_df.at[index_to_update, 'K1_PIXEL_THRESHOLD'] = skin_threshold\n","                # Save the frames\n","                cv2.imwrite(k1_display_frame_path, sig_extractor.display_frame)\n","                cv2.imwrite(k1_skin_frame_path, sig_extractor.display_skin_frame)\n","                # Save the instance dataframe\n","                instance_df.to_json(instance_filename)\n","\n","        \n","        # Process the K2 video if we can\n","        if instance_df.at[index_to_update, 'K2_SKIN_RECTANGLE_COORDS'] == [-1, -1, -1, -1]:\n","            # Check if the K2 video exists\n","            if instance_df.loc[instance_df['INSTANCE'] == int(instance), 'K2_PATH'].values[0] is None:\n","                continue\n","            else:\n","                # Reset the sig_extractor\n","                sig_extractor.skin_extractor.mean_rgb = None\n","                sig_extractor.skin_extractor.rect = None\n","                sig_extractor.display_frame = None\n","                sig_extractor.skin_frame = None\n","                # Get the video path for the K2\n","                videoFilename = instance_df.loc[instance_df['INSTANCE'] == int(instance), 'K2_PATH'].values[0]\n","                # Get the values\n","                hol_sig = sig_extractor.extract_holistic_rectangle(videoFilename,skin_threshold)\n","                # Add the values to the dataframe\n","                instance_df.at[index_to_update, 'K2_SKIN_RECTANGLE_COORDS'] = tuple(sig_extractor.skin_extractor.rect)\n","                instance_df.at[index_to_update, 'K2_SKIN_RECTANGLE_MEAN_RGB'] = sig_extractor.skin_extractor.mean_rgb.tolist()\n","                instance_df.at[index_to_update, 'K2_PIXEL_THRESHOLD'] = skin_threshold\n","                # Save the frames\n","                cv2.imwrite(k2_display_frame_path, sig_extractor.display_frame)\n","                cv2.imwrite(k2_skin_frame_path, sig_extractor.display_skin_frame)\n","                # Save the instance dataframe\n","                instance_df.to_json(instance_filename)\n","\n","    # read in the saved instance dataframe\n","    instance_df = pd.read_json(instance_filename)\n","            \n","    return instance_df"]},{"cell_type":"markdown","metadata":{},"source":["## Process Holistic Function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def holistic_process_video(instance,\n","                            camera,\n","                            instance_df, \n","                            groundtruth_df, \n","                            results_path, \n","                            sig_extractor, \n","                            methods,\n","                            deep_methods, \n","                            window_info, \n","                            seconds, \n","                            pixel_thresholds, \n","                            frequency_bandpass):\n","    \"\"\" \n","    Runs the pipeline on a specific video file.\n","\n","    Args:\n","        instance (int):\n","            - The specific instance we want to analyze\n","        camera (str):\n","            - Either \"K1\" or \"K2\", specifies the camera we want to use \n","        instance_df (pd.DataFrame):\n","            - The instance dataframe containing paths to the videos and other information\n","        groundtruth_df (pd.DataFrame):\n","            - The groundtruth dataframe containing the BPM and time data\n","        results_path (str):\n","            - The path to save the results\n","        sig_extractor (pyVHR.extraction.SignalProcessing):\n","            - The signal extractor object\n","        methods (list):\n","            - The list of methods to use for the traditional processing\n","        deep_methods (list):\n","            - The list of methods to use for the deep processing\n","        window_info (list):\n","            - The window size and stride for the traditional processing\n","        seconds (int):\n","            - The number of seconds to process\n","        pixel_thresholds (list): \n","            - The pixel thresholds for the traditional processing\n","        frequency_bandpass (list):\n","            - The frequency bandpass for the traditional processing\n","    \"\"\"\n","\n","    # Set up the variables\n","    wsize = window_info[0]\n","    stride = window_info[1]\n","    low_thr = pixel_thresholds[0]\n","    high_thr = pixel_thresholds[1]\n","    low_hz = frequency_bandpass[0]\n","    high_hz = frequency_bandpass[1]\n","\n","    # Get the index of the instance\n","    index = instance_df[instance_df['INSTANCE'] == int(instance)].index[0]\n","\n","    # Load the relevant information from the instance_df\n","    videoFilename = instance_df.at[index, camera + '_PATH']\n","    skin_threshold = instance_df.at[index, camera + '_PIXEL_THRESHOLD']\n","    mean_rgb = instance_df.at[index, camera + '_SKIN_RECTANGLE_MEAN_RGB']\n","\n","    # Update the sig_extractor based on this video\n","    fps = vhr.extraction.get_fps(videoFilename)\n","    sig_extractor.set_total_frames(fps*seconds)\n","    sig_extractor.skin_extractor.mean_rgb = mean_rgb\n","\n","    # Try load the groundtruth data from the groundtruth_df\n","    # Signal types to check\n","    signal_types = ['ECG', 'ABP', 'CVP']\n","\n","    # Initialize variables\n","    bpmGT = None\n","    timesGT = None\n","    signal_type = None\n","\n","    # Try to load the ground truth data\n","    try:\n","        for signal_type in signal_types:\n","            bpm_values = groundtruth_df.at[index, f'{signal_type}_BPM']\n","            times_values = groundtruth_df.at[index, f'{signal_type}_TIMES']\n","            \n","            if not np.isnan(bpm_values[0]):\n","                bpmGT = bpm_values\n","                timesGT = times_values\n","                signal_type = signal_type\n","                break\n","    except Exception as e:\n","        print(f\"Error in loading ground truth data: {e}\")\n","\n","    if signal_type is None:\n","        print(\"No groundtruth data found for this instance.\")\n","        return instance_df, groundtruth_df, sig_extractor\n","\n","    # Get the holistic signal for the raw frames\n","    try:\n","        hol_sig = sig_extractor.extract_holistic_rectangle(videoFilename,skin_threshold,segmented_frames = False)\n","        windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps)\n","        filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': low_thr, 'RGB_HIGH_TH': high_thr})\n","        filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","        for method in methods:\n","            results_df = pd.read_json(os.path.join(results_path, f\"holistic_{method}.json\"))\n","            if method == \"CHROM\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","            elif method == \"LGI\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI)\n","            elif method == \"POS\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","            elif method == \"PBV\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV)\n","            elif method == \"PCA\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","            elif method == \"GREEN\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN)\n","            elif method == \"OMIT\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT)\n","            elif method == \"ICA\":\n","                hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","            else:\n","                print(f\"Method {method} not recognized. Skipping.\")\n","                break\n","            hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","            hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)\n","            if method == \"PCA\":\n","                hol_bpmES = [x[0] for x in hol_bpmES]\n","            if method == \"ICA\":\n","                hol_bpmES = [x[0] for x in hol_bpmES]\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT, timesES, timesGT)\n","            # Update the results_dataframes\n","            results_df.at[index, 'INSTANCE'] = instance\n","            results_df.at[index, 'GT'] = signal_type\n","            results_df['TIMES'] = results_df['TIMES'].astype('object')\n","            results_df.at[index, 'TIMES'] = timesES\n","            results_df[camera+'_BPM_RAW'] = results_df[camera+'_BPM_RAW'].astype('object')\n","            hol_bpmES = [x.item() for x in hol_bpmES]\n","            results_df.at[index, camera+'_BPM_RAW'] = hol_bpmES\n","            results_df.at[index, camera+'_RMSE_RAW'] = RMSE.tolist()\n","            results_df.at[index, camera+'_MAE_RAW'] = MAE.tolist()\n","            results_df.at[index, camera+'_PCC_RAW'] = PCC.tolist()\n","            results_df.at[index, camera+'_CCC_RAW'] = CCC.tolist()\n","            results_df.at[index, camera+'_SNR_RAW'] = SNR.tolist()\n","\n","            # Save the results_df\n","            results_df = results_df.convert_dtypes()\n","            results_df.to_json(os.path.join(results_path, f\"holistic_{method}.json\"))\n","\n","    except Exception as e:\n","        print(f\"Error in processing the raw holistic signal: {e}\")\n","\n","    # Get the holistic signal for the raw frames\n","    hol_sig = sig_extractor.extract_holistic_rectangle(videoFilename,skin_threshold,segmented_frames = True)\n","    windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps)\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': low_thr, 'RGB_HIGH_TH': high_thr})\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","    for method in methods:\n","        results_df = pd.read_json(os.path.join(results_path, f\"holistic_{method}.json\"))\n","        if method == \"CHROM\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","        elif method == \"LGI\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI)\n","        elif method == \"POS\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","        elif method == \"PBV\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV)\n","        elif method == \"PCA\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","        elif method == \"GREEN\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN)\n","        elif method == \"OMIT\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT)\n","        elif method == \"ICA\":\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","        else:\n","            print(f\"Method {method} not recognized. Skipping.\")\n","            break\n","        hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","        hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)\n","        if method == \"PCA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","        if method == \"ICA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","        RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT, timesES, timesGT)\n","        # Update the results_dataframes\n","        results_df.at[index, 'INSTANCE'] = instance\n","        results_df.at[index, 'GT'] = signal_type\n","        results_df['TIMES'] = results_df['TIMES'].astype('object')\n","        results_df.at[index, 'TIMES'] = timesES\n","        results_df[camera+'_BPM_SEGMENTED'] = results_df[camera+'_BPM_SEGMENTED'].astype('object')\n","        hol_bpmES = [x.item() for x in hol_bpmES]\n","        results_df.at[index, camera+'_BPM_SEGMENTED'] = hol_bpmES\n","        results_df.at[index, camera+'_RMSE_SEGMENTED'] = RMSE.tolist()\n","        results_df.at[index, camera+'_MAE_SEGMENTED'] = MAE.tolist()\n","        results_df.at[index, camera+'_PCC_SEGMENTED'] = PCC.tolist()\n","        results_df.at[index, camera+'_CCC_SEGMENTED'] = CCC.tolist()\n","        results_df.at[index, camera+'_SNR_SEGMENTED'] = SNR.tolist()\n","\n","        # Save the results_df\n","        results_df = results_df.convert_dtypes()\n","        results_df.to_json(os.path.join(results_path, f\"holistic_{method}.json\"))\n","\n","    ############ Deep Processing ############\n","\n","    # Get the raw and segmented frames for the deep learning models\n","    frames = sig_extractor.extract_raw(videoFilename)\n","    #print(frames.shape)\n","    skin_frames = np.array(sig_extractor.visualize_skin_collection)\n","    #print(skin_frames.shape)\n","\n","    for method in deep_methods:\n","        print(f\"Processing {method} - Deep Holistic\")\n","        deep_results_df = pd.read_json(os.path.join(results_path, f\"deep_holistic_{method}.json\"))\n","        deep_results_df.at[index, 'INSTANCE'] = instance\n","        deep_results_df.at[index, 'GT'] = signal_type\n","        deep_results_df['TIMES'] = deep_results_df['TIMES'].astype('object')\n","        deep_results_df[camera+'_BPM_RAW'] = deep_results_df[camera+'_BPM_RAW'].astype('object')\n","        deep_results_df[camera+'_BPM_SEGMENTED'] = deep_results_df[camera+'_BPM_SEGMENTED'].astype('object')\n","\n","        if method == 'MTTS_CAN':\n","            # first do the raw frames\n","            bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(frames, fps, verb=0)\n","            bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","            bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","            bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps) \n","            RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","            deep_results_df.at[index, 'TIMES'] = timesES\n","            deep_results_df.at[index, camera+'_BPM_RAW'] = [x.item() for x in bpmES]\n","            deep_results_df.at[index, camera+'_RMSE_RAW'] = RMSE.tolist()\n","            deep_results_df.at[index, camera+'_MAE_RAW'] = MAE.tolist()\n","            deep_results_df.at[index, camera+'_PCC_RAW'] = PCC.tolist()\n","            deep_results_df.at[index, camera+'_CCC_RAW'] = CCC.tolist()\n","            deep_results_df.at[index, camera+'_SNR_RAW'] = SNR.tolist()\n","            # Now do the segmented frames\n","            bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(skin_frames, fps, verb=0)\n","            bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","            bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","            bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","            RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","            deep_results_df.at[index, camera+'_BPM_SEGMENTED'] = [x.item() for x in bpmES]\n","            deep_results_df.at[index, camera+'_RMSE_SEGMENTED'] = RMSE.tolist()\n","            deep_results_df.at[index, camera+'_MAE_SEGMENTED'] = MAE.tolist()\n","            deep_results_df.at[index, camera+'_PCC_SEGMENTED'] = PCC.tolist()\n","            deep_results_df.at[index, camera+'_CCC_SEGMENTED'] = CCC.tolist()\n","            deep_results_df.at[index, camera+'_SNR_SEGMENTED'] = SNR.tolist()\n","            # Save the results_df\n","            deep_results_df = deep_results_df.convert_dtypes()\n","            deep_results_df.to_json(os.path.join(results_path, f\"deep_holistic_{method}.json\"))\n","        elif method == 'HR_CNN':\n","            # apply HR_CNN model\n","            bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(frames)\n","            bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # raw BVP object, mostly to set up sample rate\n","            bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","            bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","            RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","            deep_results_df.at[index, camera+'_BPM_RAW'] = [x.item() for x in bpmES]\n","            deep_results_df.at[index, camera+'_RMSE_RAW'] = RMSE.tolist()\n","            deep_results_df.at[index, camera+'_MAE_RAW'] = MAE.tolist()\n","            deep_results_df.at[index, camera+'_PCC_RAW'] = PCC.tolist()\n","            deep_results_df.at[index, camera+'_CCC_RAW'] = CCC.tolist()\n","            deep_results_df.at[index, camera+'_SNR_RAW'] = SNR.tolist()\n","            # Now do the segmented frames\n","            bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(skin_frames)\n","            bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","            bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","            bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","            RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","            deep_results_df.at[index, camera+'_BPM_SEGMENTED'] = [x.item() for x in bpmES]\n","            deep_results_df.at[index, camera+'_RMSE_SEGMENTED'] = RMSE.tolist()\n","            deep_results_df.at[index, camera+'_MAE_SEGMENTED'] = MAE.tolist()\n","            deep_results_df.at[index, camera+'_PCC_SEGMENTED'] = PCC.tolist()\n","            deep_results_df.at[index, camera+'_CCC_SEGMENTED'] = CCC.tolist()\n","            deep_results_df.at[index, camera+'_SNR_SEGMENTED'] = SNR.tolist()\n","            # Save the results_df\n","            deep_results_df = deep_results_df.convert_dtypes()\n","            deep_results_df.to_json(os.path.join(results_path, f\"deep_holistic_{method}.json\"))\n","        else:\n","            print(\"Method not found\")\n","            continue\n","\n","    return instance_df, groundtruth_df, sig_extractor"]},{"cell_type":"markdown","metadata":{},"source":["## Process Patch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def patch_process_instance(instance,\n","                            camera,\n","                            instance_df, \n","                            groundtruth_df, \n","                            results_path, \n","                            sig_extractor, \n","                            methods,\n","                            deep_methods, \n","                            window_info, \n","                            seconds,\n","                            pixel_thresholds, \n","                            frequency_bandpass):\n","    # Patch process for a single instance, with a bunch of methods\n","    # Return the instance_df, groundtruth_df and the sig_extractor. \n","\n","    # Create a sub_folder for the instance\n","    figure_dir = os.path.join(results_path, \"figures\")\n","    instance_figure_dir = os.path.join(figure_dir, f\"{instance}\")\n","    os.makedirs(instance_figure_dir, exist_ok=True)\n","\n","\n","    # Save the display_image and the skin_image to the instance_figure_dir\n","    # convert from BGR to RGB first\n","    display_image = cv2.cvtColor(sig_extractor.display_frame, cv2.COLOR_BGR2RGB)\n","    skin_image = cv2.cvtColor(sig_extractor.display_skin_frame, cv2.COLOR_BGR2RGB)\n","    cv2.imwrite(os.path.join(instance_figure_dir, f\"{camera}_display_image.png\"), display_image)\n","    cv2.imwrite(os.path.join(instance_figure_dir, f\"{camera}_skin_image.png\"), skin_image)\n","\n","    # Set up the variables\n","    wsize = window_info[0]\n","    stride = window_info[1]\n","    low_thr = pixel_thresholds[0]\n","    high_thr = pixel_thresholds[1]\n","    low_hz = frequency_bandpass[0]\n","    high_hz = frequency_bandpass[1]\n","    patch_shape = (int(sig_extractor.square),int(sig_extractor.square))\n","    overlap = sig_extractor.overlap\n","\n","    # Get the index of the instance\n","    index = instance_df[instance_df['INSTANCE'] == int(instance)].index[0]\n","\n","    # Try load the groundtruth data from the groundtruth_df\n","    # Signal types to check\n","    signal_types = ['ECG', 'ABP', 'CVP']\n","\n","    # Initialize variables\n","    bpmGT = None\n","    timesGT = None\n","    signal_type = None\n","\n","    # Try to load the ground truth data\n","    for s_type in signal_types:\n","        bpm_values = groundtruth_df.at[index, f'{s_type}_BPM']\n","        times_values = groundtruth_df.at[index, f'{s_type}_TIMES']\n","        \n","        if not np.isnan(bpm_values[0]):\n","            bpmGT = bpm_values\n","            timesGT = times_values\n","            signal_type = s_type\n","            break\n","\n","    if signal_type is None:\n","        print(\"No groundtruth data found for this instance.\")\n","        return instance_df, groundtruth_df, sig_extractor\n","\n","    # Get relevant info from the instance_df\n","    videoFilename = instance_df.at[index, camera + '_PATH']\n","\n","    # Update the sig extractor\n","    fps = vhr.extraction.get_fps(videoFilename)\n","    sig_extractor.set_total_frames(fps*seconds)\n","    sig_extractor.set_fixed_patches(videoFilename,region_type=\"squares\",overlap=overlap)\n","    sig_extraction_method = \"mean\"\n","\n","    # Get the patch signal\n","    try:\n","        patch_sig = sig_extractor.extract_fixed_patches(sig_extraction_method,segmented_frames = True)\n","    except Exception as e:\n","        print(f\"Error in extracting the patch signal {instance} {camera}: {e}\")\n","    # Window the patch_signal\n","    try:\n","        windowed_patch_sig, timesES = vhr.extraction.sig_windowing(patch_sig, wsize, stride, fps)\n","    except Exception as e:\n","        print(f\"Error in windowing the patch signal {instance} {camera}: {e}\")\n","    # Pixel threshold the signal\n","    try:\n","        filtered_windowed_patch_sig, patch_ids = vhr.BVP.apply_custom_filter(windowed_patch_sig, vhr.BVP.rgb_filter_th_with_ids, params={'RGB_LOW_TH': low_thr, 'RGB_HIGH_TH': high_thr})\n","    except Exception as e:\n","        print(f\"Error in pixel thresholding the patch signal {instance} {camera}: {e}\")\n","    # Bandpass the signal\n","    try:\n","        filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","    except Exception as e:\n","        print(f\"Error in bandpassing the patch signal {instance} {camera}: {e}\")\n","\n","    # Update the instance_df\n","    try:\n","        instance_df[camera+'_PATCH_IDS'] = instance_df[camera+'_PATCH_IDS'].astype('object')\n","        instance_df.at[index, camera+'_PATCH_IDS'] = [array.tolist() for array in patch_ids]\n","    except Exception as e:\n","        print(f\"Error in updating the instance_df {instance} {camera}: {e}\")\n","\n","    # Loop through the methods\n","    for method in methods:\n","        try:\n","            results_df = pd.read_json(os.path.join(results_path, f\"patch_{method}.json\"))\n","        except Exception as e:\n","            print(f\"Error in reading the results_df for {instance} {camera} {method}: {e}\")\n","            continue\n","        # Update the first few columns of the dataframe\n","        try:\n","            results_df.at[index, 'INSTANCE'] = instance\n","            results_df.at[index, 'GT'] = signal_type\n","            results_df['TIMES'] = results_df['TIMES'].astype('object')\n","            results_df.at[index, 'TIMES'] = timesES\n","        except Exception as e:\n","            print(f\"Error in updating the results_df for  {instance} {camera} {method}: {e}\")\n","            continue\n","\n","        if method == \"CHROM\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_CHROM)\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"LGI\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_LGI)\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"POS\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"PBV\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_PBV)\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"PCA\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"GREEN\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_GREEN)\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"OMIT\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_OMIT)\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        elif method == \"ICA\":\n","            try:\n","                patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","            except Exception as e:\n","                print(f\"Error in processing the patch signal with  {instance} {camera} {method}: {e}\")\n","                continue\n","        else:\n","            print(\"Method not found\")\n","            continue\n","\n","        # Post processing bandpass filter\n","        try:\n","            patch_bvps = vhr.BVP.apply_filter(patch_bvps, BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","        except Exception as e:\n","            print(f\"Error in post processing the patch signal with  {instance} {camera} {method}: {e}\")\n","            continue\n","        \n","        # Get the bpm estimates for all the patches\n","        try:\n","            patch_bpmES = vhr.BPM.BVP_to_BPM_cuda(patch_bvps, fps)\n","        except Exception as e:\n","            print(f\"Error in getting the bpm estimates for  {instance} {camera} {method}: {e}\")\n","            continue\n","        \n","        try:\n","            sig_extractor.fixed_patches = add_fixed_patch_info(sig_extractor.fixed_patches,patch_ids,patch_bvps,patch_bpmES,timesES)\n","        except Exception as e:\n","            print(f\"Error in adding the patch info to sig_extractor {instance} {camera} {method}: {e}\")\n","            continue\n","\n","        try:\n","            sig_extractor.fixed_patches = update_patch_metrics(sig_extractor.fixed_patches,timesGT,bpmGT,fps)\n","        except Exception as e:\n","            print(f\"Error in updating the patch metrics {instance} {camera} {method}: {e}\")\n","\n","        # make the patch dataframe which we will then save\n","        try:\n","            patch_df = make_patch_dataframe(sig_extractor.fixed_patches)\n","        except Exception as e:\n","            print(f\"Error in making the patch dataframe for instance {instance} {camera} {method}: {e}\")\n","            continue\n","\n","        try:\n","            patch_df_dir = os.path.join(results_path, \"patch_dataframes\", str(instance))\n","            os.makedirs(patch_df_dir, exist_ok=True)\n","            patch_df.to_json(os.path.join(patch_df_dir, f\"{method}_{camera}_patch_df.json\"))\n","        except Exception as e:\n","            print(f\"Error in saving the patch dataframe at instance {instance} {camera} {method}: {e}\")\n","            continue\n","\n","        try:\n","            for fixed_patch in sig_extractor.fixed_patches:\n","                fixed_patch.times = []\n","                fixed_patch.bvps = []\n","                fixed_patch.bpms = []\n","                fixed_patch.snrs = []\n","                fixed_patch.rmse = 0\n","                fixed_patch.mae = 0\n","                fixed_patch.max = 0\n","        except Exception as e:\n","            print(f\"Error in resetting the fixed patches  of sig_extractor {instance} {camera} {method}: {e}\")\n","            continue\n","\n","\n","        bpm_estimation_methods = [\"MED\", \"PSD\"]\n","\n","        for est_method in bpm_estimation_methods:\n","            if est_method == \"MED\":\n","                bpmES, MAD = vhr.BPM.BPM_median(patch_bpmES)\n","\n","            if est_method == \"PSD\":\n","                ma = vhr.extraction.MotionAnalysis(sig_extractor, wsize, fps)\n","                bpmES = vhr.BPM.BPM_clustering(ma, patch_bvps, fps, wsize, movement_thrs=None, opt_factor=0.5)\n","\n","            try:\n","                RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, bpmES, bpmGT, timesES, timesGT)\n","                results_df[camera+'_'+est_method+'_BPM'] = results_df[camera+'_'+est_method+'_BPM'].astype('object')\n","                bpmES = [x.item() for x in bpmES]\n","            except Exception as e:\n","                print(f\"Error in getting the errors for {instance} {camera} method {method} and est_method {est_method}: {e}\")\n","                continue\n","            \n","            try:\n","                results_df.at[index, camera+'_'+est_method+'_BPM'] = bpmES\n","                results_df.at[index, camera+'_'+est_method+'_RMSE'] = RMSE.tolist()\n","                results_df.at[index, camera+'_'+est_method+'_MAE'] = MAE.tolist()\n","                results_df.at[index, camera+'_'+est_method+'_PCC'] = PCC.tolist()\n","                results_df.at[index, camera+'_'+est_method+'_CCC'] = CCC.tolist()\n","                results_df.at[index, camera+'_'+est_method+'_SNR'] = SNR.tolist()\n","            except Exception as e:\n","                print(f\"Error in updating the results_df for {instance} {camera} method {method} and est_method {est_method}: {e}\")\n","                continue\n","\n","            try:\n","                # Save the results_df\n","                results_df.to_json(os.path.join(results_path, f\"patch_{method}.json\"))\n","                print(f'successfully saved the results_df for camera {camera}, method {method} and est_method {est_method}')\n","            except Exception as e:\n","                print(f\"Error in saving the results_df for instance {instance} {camera} {method} and est_method {est_method}: {e}\")\n","                continue\n","\n","            \"\"\"            \n","            # Make the folders for saving some figures\n","            try:\n","                estimated_fig_dir = os.path.join(instance_figure_dir, f\"{method}_{est_method}_{camera}_estimated\")\n","                error_fig_dir = os.path.join(instance_figure_dir, f\"{method}_{est_method}_{camera}_error\")\n","                os.makedirs(estimated_fig_dir, exist_ok=True)\n","                os.makedirs(error_fig_dir, exist_ok=True)\n","            except Exception as e:\n","                print(f\"Error in making the figure directories for method {method} and est_method {est_method}: {e}\")\n","                continue\n","\n","            # Get the figures\n","            image = sig_extractor.display_frame\n","            try:\n","                for wind in range(len(patch_bvps)):\n","                    ldmks, fig1 = vhr.plot.visualize_BVPs_heatmap(image, patch_bvps, patch_ids, wind, patch_shape, overlap, fps, minHz=0.65, maxHz=4)\n","                    fig2 = vhr.plot.visualize_BPM_Errors_heatmap(image, ldmks, timesES, wind, timesGT, bpmGT, patch_shape, overlap,vmin=-20,vmax=20)\n","                    fig1_path = os.path.join(estimated_fig_dir, f\"{wind}.png\")\n","                    fig2_path = os.path.join(error_fig_dir, f\"{wind}.png\")\n","                    cv2.imwrite(fig1_path, fig1)\n","                    cv2.imwrite(fig2_path, fig2)\n","            except Exception as e:\n","                print(f\"Error in getting the figures for method {method} and est_method {est_method}: {e}\")\n","                continue\n","            \"\"\"\n","\n","    # save the instance_df\n","    try:\n","        instance_df.to_json(os.path.join(results_path, \"instance_info.json\"))\n","    except Exception as e:\n","        print(f\"Error in saving the instance_df: {e}\")\n","        return instance_df, groundtruth_df, sig_extractor\n","\n","\n","    return instance_df, groundtruth_df, sig_extractor"]},{"cell_type":"markdown","metadata":{},"source":["## User Inputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## User input parameters\n","dataset_name = 'CVP'\n","window_info = [8,1]     # window size and stride\n","seconds = 0     # seconds of video to be processed (0 for all video)\n","skin_threshold = 30    # threshold for skin extraction\n","pixel_thresholds = [75,230] #low and high thresholding\n","frequency_bandpass = [0.65,4.0] # bandpass range\n","patch_info = [10.,0] # size, pixel overlap\n","\n","vhr.extraction.SkinProcessingParams.RGB_LOW_TH =  pixel_thresholds[0]\n","vhr.extraction.SkinProcessingParams.RGB_HIGH_TH = pixel_thresholds[1]\n","\n","vhr.extraction.SignalProcessingParams.RGB_LOW_TH = pixel_thresholds[0]\n","vhr.extraction.SignalProcessingParams.RGB_HIGH_TH = pixel_thresholds[1]"]},{"cell_type":"markdown","metadata":{},"source":["### Create the dataframes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_path = \"C:\\\\Users\\\\20759193\\\\source\\\\repos\\\\pyVHR\\\\results\"\n","base_path = \"C:\\\\Users\\\\20759193\\\\source\\\\repos\\\\pyVHR\\\\data\"\n","dataset_name = 'CVP'\n","methods = ['CHROM','LGI','POS','PBV','PCA','GREEN','OMIT','ICA','PCA']\n","deep_methods = ['HR_CNN','MTTS_CAN']\n","dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=\"\", BVPdataDIR=\"\")\n","instance_df = create_instance_dataframe(results_path, base_path)\n","groundtruth_df = create_groundtruth_dataframe(instance_df, results_path)\n","create_holistic_dataframes(methods, results_path)\n","create_patch_dataframes(methods, results_path)\n","create_deep_holistic_dataframes(deep_methods, results_path)\n","#create_deep_patch_dataframes(deep_methods, results_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Populate the groundtruth df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["instance_df, groundtruth_df = populate_groundtruth_df(instance_df, results_path, dataset, window_info=window_info)"]},{"cell_type":"markdown","metadata":{},"source":["### Segment the skin for all the frames"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["instance_df = get_skin_segmentation_info(instance_df,results_path,skin_threshold)"]},{"cell_type":"markdown","metadata":{},"source":["# Test instance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["instances = instance_df['INSTANCE'].values\n","cameras = ['K1','K2']\n","# loop through them using tqdm, with a description\n","for instance in tqdm(instances[0:1], desc=\"Processing instance:\"):\n","    for camera in cameras:\n","        try:\n","            sig_extractor = initialize_sig_extractor(seconds=seconds,patch_info = patch_info)\n","            instance_df, groundtruth_df, sig_extractor = holistic_process_video(instance,\n","                                    camera,\n","                                    instance_df, \n","                                    groundtruth_df, \n","                                    results_path, \n","                                    sig_extractor, \n","                                    methods,\n","                                    deep_methods, \n","                                    window_info, \n","                                    seconds, \n","                                    pixel_thresholds, \n","                                    frequency_bandpass)\n","        except:\n","            print(f\"Error processing holistic instance {instance} for camera {camera}\")\n","            continue\n","        \n","        try:\n","            instance_df, groundtruth_df, sig_extractor = patch_process_instance(instance,\n","                                    camera,\n","                                    instance_df, \n","                                    groundtruth_df, \n","                                    results_path, \n","                                    sig_extractor, \n","                                    methods,\n","                                    deep_methods, \n","                                    window_info, \n","                                    seconds, \n","                                    pixel_thresholds, \n","                                    frequency_bandpass)\n","        except:\n","            print(f\"Error processing patch instance {instance} for camera {camera}\")\n","            continue       \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = make_patch_dataframe(sig_extractor.fixed_patches)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Process Videos"]},{"cell_type":"markdown","metadata":{},"source":["### Function for single video processing patches"]},{"cell_type":"markdown","metadata":{},"source":["### Running the processing functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_name = 'CVP'\n","window_info = [8,1]     # window size and stride\n","seconds = 0     # seconds of video to be processed (0 for all video)\n","skin_threshold = 40    # threshold for skin extraction\n","pixel_thresholds = [5,250] #low and high thresholding\n","frequency_bandpass = [0.75,200/60] # bandpass range\n","patch_info = [40.,30] # size, pixel overlap\n","methods = ['CHROM', 'LGI', 'POS', 'PBV', 'GREEN', 'OMIT','ICA','PCA']\n","instance = 100\n","camera = \"K1\"\n","\n","sig_extractor = initialize_sig_extractor(seconds=seconds,patch_info=patch_info)\n","\n","print(\"Processing Holistic\")\n","instance_df,groundtruth_df,sig_extractor = holistic_process_instance(instance,\n","                            camera,\n","                            instance_df, \n","                            groundtruth_df, \n","                            results_path, \n","                            sig_extractor, \n","                            methods, \n","                            window_info, \n","                            seconds, \n","                            skin_threshold, \n","                            pixel_thresholds, \n","                            frequency_bandpass)\n","print(\"Holistic finished: Processing Patch\")\n","instance_df,groundtruth_df,sig_extractor = patch_process_instance(instance,\n","                            camera,\n","                            instance_df, \n","                            groundtruth_df, \n","                            results_path, \n","                            sig_extractor, \n","                            methods, \n","                            window_info, \n","                            seconds, \n","                            skin_threshold, \n","                            pixel_thresholds, \n","                            frequency_bandpass)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["method = \"PCA\"\n","results_df = pd.read_json(os.path.join(results_path, f\"patch_{method}.json\"))\n","results_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Another thing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def holistic_processing(instances_df,groundtruth_df,sig_extractor,methods,skin_threshold = 30,window_info = [8,1],pixel_thresholds = [5,230],frequency_bandpass = [0.65,4]):\n","    \"\"\"\n","    Performs Holistic processing on a video to obtain BVP signals using various methods.\n","    \n","    Parameters:\n","    - Various parameters as required by internal processing\n","    \"\"\"\n","    wsize = window_info[0]\n","    stride = window_info[1]\n","    skin_threshold = skin_threshold\n","    low_thr = pixel_thresholds[0]\n","    high_thr = pixel_thresholds[1]\n","    low_hz = frequency_bandpass[0]\n","    high_hz = frequency_bandpass[1]\n","\n","\n","    # Set the paths\n","    path, videoFilename, sigFilename = get_paths(df,instance,camera)\n","\n","    # Load the best groundtruth we have\n","    bpmGT,timesGT = get_groundtruth(df, instance, camera)\n","\n","    # Get fps\n","    fps = vhr.extraction.get_fps(videoFilename)\n","\n","    # Extract the skin\n","    hol_sig = sig_extractor.extract_holistic_rectangle(videoFilename,skin_threshold)\n","    \n","    # Window the signal\n","    windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps)\n","\n","    # Preprocess \n","    # Pixel Thresholding\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': low_thr, 'RGB_HIGH_TH': high_thr})\n","    \n","    # Bandpass\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","\n","    for method in methods:\n","        if method == \"CHROM\":\n","            print(\"Processing CHROM - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","        elif method == \"LGI\":\n","            print(\"PROCESSING LGI - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI)\n","        elif method == \"POS\":\n","            print(\"PROCESSING POS - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","        elif method == \"PBV\":\n","            print(\"PROCESSING PBV - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV)\n","        elif method == \"PCA\":\n","            print(\"PROCESSING PCA - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","        elif method == \"GREEN\":\n","            print(\"PROCESSING GREEN - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN)\n","        elif method == \"OMIT\":\n","            print(\"PROCESSING OMIT - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT)\n","        elif method == \"ICA\":\n","            print(\"PROCESSING ICA - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","        else:\n","            print(\"Method not found\")\n","            continue\n","\n","        # Post-processing signals\n","        # Bandpass\n","        hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':low_hz,'maxHz':high_hz,'fps':fps})\n","\n","        # Get the BPM Estimates\n","        hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)\n","        if method == \"PCA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","        if method == \"ICA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","\n","        # Holistic errors\n","        RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT, timesES, timesGT)\n","\n","        # Store the results\n","        ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","        OUTPUT = [timesES, hol_bpmES, ERRORS]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'HOL_' + method + '_' + camera] = OUTPUT\n","    \n","    return df, sig_extractor\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def deep_processing(df,instance,camera,sig_extractor,window_info = [8,1]):\n","\n","    # Set parameters\n","    wsize = window_info[0]\n","    stride = window_info[1]\n","\n","    # Load the best groundtruth we have\n","    bpmGT,timesGT = get_groundtruth(df, instance, camera)\n","    path, videoFilename, sigFilename = get_paths(df,instance,camera)\n","\n","    # Get the two different holistics to process\n","    fps = vhr.extraction.get_fps(videoFilename)\n","    raw_frames = sig_extractor.extract_raw(videoFilename)\n","    skin_frames = np.array(sig_extractor.visualize_skin_collection)\n","\n","####################   MTTS_CAN   ####################\n","    # Predict bvp for raw_frames\n","    bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(raw_frames, fps, verb=1)\n","    # Window bvp\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=stride)\n","    # Estimates\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    # Errors\n","    RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","    # Store the results\n","    ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","    OUTPUT = [timesES, bpmES, ERRORS]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'DEEP_MTTS_CAN_FULL_' + camera] = OUTPUT\n","\n","    # Segmented Frames\n","    bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(skin_frames, fps, verb=1)\n","    # Window bvp\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=stride)\n","    # Estimates\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    # Errors\n","    RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","    # Store the results\n","    ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","    OUTPUT = [timesES, bpmES, ERRORS]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'DEEP_MTTS_CAN_SEGMENTED_' + camera] = OUTPUT\n","\n","\n","####################   HR_CNN   ####################\n","    # Predict bvp for raw_frames\n","    bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(raw_frames)\n","    # Window bvp\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=stride)\n","    # Estimates\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    # Errors\n","    RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","    # Store results\n","    ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","    OUTPUT = [timesES, bpmES, ERRORS]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'DEEP_HR_CNN_FULL_' + camera] = OUTPUT\n","\n","    # Segmented Frames\n","    bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(skin_frames)\n","    # Window bvp\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=stride)\n","    # Estimates\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    # Errors\n","    RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","    # Store the results\n","    ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","    OUTPUT = [timesES, bpmES, ERRORS]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'DEEP_HR_CNN_SEGMENTED_' + camera] = OUTPUT\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def patch_processing(sig_extractor, vhr, videoFileName, wsize, fps, methods):\n","    \"\"\"\n","    Performs Patch processing on a video to obtain BVP signals using various methods.\n","    \n","    Parameters:\n","    - Various parameters as required by internal processing\n","    \"\"\"\n","    # Set landmarks and extraction method\n","    sig_extractor.set_square_patches_side(40.)\n","    sig_extractor.set_fixed_landmarks(videoFileName, region_type=\"squares\", overlap=20)\n","    patch_sig = sig_extractor.extract_fixed_patches(\"mean\")\n","    \n","    # Window and filter the signal\n","    windowed_patch_sig, _ = vhr.extraction.sig_windowing(patch_sig, wsize, 1, fps)\n","    filtered_windowed_patch_sig, _ = vhr.BVP.apply_custom_filter(windowed_patch_sig, vhr.BVP.rgb_filter_th_with_ids, params={'RGB_LOW_TH': 5, 'RGB_HIGH_TH': 230})\n","    \n","    patch_bvps = {}  # Initialize an empty dictionary to store BVP signals\n","    \n","    for method in methods:\n","        print(f\"PROCESSING {method} - Patches\")\n","        \n","        # Device type and method mapping\n","        device_type = 'cuda' if method in ['CHROM', 'POS'] else 'cpu'\n","        \n","        # Process and store the BVP signal\n","        patch_bvps[method] = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type=device_type, method=method)\n","    \n","    return patch_bvps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_video(df,instance,camera):\n","    # Set the parameters\n","    seconds = 0     # seconds of video to be processed (0 for all video)\n","    pixel_threshold = 30\n","    wsize = 8\n","    dataset_name = 'CVP'\n","\n","    # Initialise everything\n","    path = df.loc[df['INSTANCE'] == instance, camera + '_DATA_PATH'].values[0]\n","    videoFileName = path + camera + \"_Cropped_Colour.mkv\"\n","    fps = vhr.extraction.get_fps(videoFileName)\n","    sigFileName = path + \"data.csv\"\n","    dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=\"\", BVPdataDIR=\"\")\n","    sig_extractor = vhr.extraction.SignalProcessing()   # Set the class\n","    sig_extractor.set_visualize_skin_and_landmarks(\n","      visualize_skin=True, \n","      visualize_landmarks=True, \n","      visualize_landmarks_number=True, \n","      visualize_patch=True)\n","    sig_extractor.choose_cuda_device(0)                 # Set the GPU\n","    sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU')) # Set the skin extractor\n","    sig_extractor.set_total_frames(seconds*fps) # Set the number of frames\n","    \n","\n","    # Initialise Parameters\n","    vhr.extraction.SkinProcessingParams.RGB_LOW_TH =  5     # threshold for skin extraction\n","    vhr.extraction.SkinProcessingParams.RGB_HIGH_TH = 230   # threshold for skin extraction\n","    vhr.extraction.SignalProcessingParams.RGB_LOW_TH = 5    # threshold for signal extraction\n","    vhr.extraction.SignalProcessingParams.RGB_HIGH_TH = 230 # threshold for signal extraction\n","    sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True, visualize_landmarks_number=True, visualize_patch=True)\n","\n","    # Get the ground truth data\n","    try:\n","        sigGT_ECG = dataset.readSigfile(sigFileName, signalGT='ECG')\n","        sigGT_ECG.show_ECG = True\n","        bpmGT_ECG, timesGT_ECG = sigGT_ECG.getBPM(wsize)\n","        # Add these to the DataFrame\n","        ecg_bpms = bpmGT_ECG.tolist()\n","        ecg_times = timesGT_ECG.tolist()\n","        ECG = [ecg_times, ecg_bpms]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'ECG'] = ECG\n","    except Exception as e:\n","        print(\"ECG not found. Error:\", e)\n","        sigGT_ECG = bpmGT_ECG = timesGT_ECG = None\n","\n","    try:\n","        sigGT_ABP = dataset.readSigfile(sigFileName, signalGT='ABP')\n","        bpmGT_ABP, timesGT_ABP = sigGT_ABP.getBPM(wsize)\n","        # Add these to the DataFrame\n","        abp_bpms = bpmGT_ABP.tolist()\n","        abp_times = timesGT_ABP.tolist()\n","        ABP = [abp_times, abp_bpms]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'ABP'] = ABP\n","    except Exception as e:\n","        print(\"ABP not found. Error:\", e)\n","        sigGT_ABP = bpmGT_ABP = timesGT_ABP = None\n","\n","    try:\n","        sigGT_CVP = dataset.readSigfile(sigFileName, signalGT='CVP')\n","        bpmGT_CVP, timesGT_CVP = sigGT_CVP.getBPM(wsize)\n","        # Add these to the DataFrame\n","        cvp_bpms = bpmGT_CVP.tolist()\n","        cvp_times = timesGT_CVP.tolist()\n","        CVP = [cvp_times, cvp_bpms]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'CVP'] = CVP\n","    except Exception as e:\n","        print(\"CVP not found. Error:\", e)\n","        sigGT_CVP = bpmGT_CVP = timesGT_CVP = None\n","\n","    # For the patches, define our landmarks\n","    sig_extractor.set_square_patches_side(40.)\n","    sig_extractor.set_fixed_landmarks(videoFileName,region_type=\"squares\",overlap=20)\n","    sig_extraction_method = \"mean\"\n","\n","    # Prefilter before we use the specific method\n","    hol_sig = sig_extractor.extract_holistic_rectangle(videoFileName,pixel_threshold)    # Extract the signal\n","    patch_sig = sig_extractor.extract_fixed_patches(sig_extraction_method)\n","\n","    # Save the 10th frame just to check filtering.\n","    frames = sig_extractor.extract_raw(videoFileName)\n","    print(frames.shape)\n","    skin_frames = np.array(sig_extractor.visualize_skin_collection)\n","    print(skin_frames.shape)\n","\n","    cv2.imwrite(path + camera +'frame.png', cv2.cvtColor(frames[9], cv2.COLOR_RGB2BGR))\n","    cv2.imwrite(path +  camera +'skin_frame.png', cv2.cvtColor(skin_frames[9], cv2.COLOR_RGB2BGR))\n","\n","    # Holistic Processing\n","    windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps) # Window the signal\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': 5, 'RGB_HIGH_TH': 230}) # Apply the threshold filter\n","    filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps}) # Apply the other filter\n","\n","    # Patch Processing\n","    \n","    windowed_patch_sig, timesES = vhr.extraction.sig_windowing(patch_sig, wsize, 1, fps)\n","    filtered_windowed_patch_sig, patch_ids = vhr.BVP.apply_custom_filter(windowed_patch_sig, vhr.BVP.rgb_filter_th_with_ids, params={'RGB_LOW_TH': 5, 'RGB_HIGH_TH': 230})\n","    filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})\n","\n","    methods = ['CHROM', 'LGI', 'POS', 'PBV', 'GREEN', 'OMIT','ICA','PCA']\n","    for method in methods:\n","        if method == \"CHROM\":\n","            print(\"Processing CHROM - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","            print(\"PROCESSING CHROM - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_CHROM)\n","        elif method == \"LGI\":\n","            print(\"PROCESSING LGI - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI)\n","            print(\"Processing LGI - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_LGI)\n","        elif method == \"POS\":\n","            print(\"PROCESSING POS - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","            print(\"PROCESSING POS - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","        elif method == \"PBV\":\n","            print(\"PROCESSING PBV - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV)\n","            print(\"PROCESSING PBV - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_PBV)\n","        elif method == \"PCA\":\n","            print(\"PROCESSING PCA - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","            print(\"PROCESSING PCA - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","        elif method == \"GREEN\":\n","            print(\"PROCESSING GREEN - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN)\n","            print(\"PROCESSING GREEN - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_GREEN)\n","        elif method == \"OMIT\":\n","            print(\"PROCESSING OMIT - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT)\n","            print(\"PROCESSING OMIT - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_OMIT)\n","        elif method == \"ICA\":\n","            print(\"PROCESSING ICA - Holistic\")\n","            hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","            print(\"PROCESSING ICA - Patches\")\n","            patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","        else:\n","            print(\"Method not found\")\n","            continue\n","\n","        # Apply the filter            \n","        hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})\n","        patch_bvps = vhr.BVP.apply_filter(patch_bvps, BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})\n","\n","        # Get the heatmaps\n","        image = sig_extractor.display_frame\n","        # Create directories if they don't exist\n","        os.makedirs(os.path.join(path, f\"{method}_{camera}_estimated\"), exist_ok=True)\n","        os.makedirs(os.path.join(path, f\"{method}_{camera}_error\"), exist_ok=True)\n","\n","        for wind in range(len(patch_bvps)):\n","            # Get landmarks and visualizations\n","            ldmks, estimated_fig = vhr.plot.visualize_BVPs_heatmap(image, patch_bvps, patch_ids, wind, patch_shape, overlap, fps, minHz=0.65, maxHz=4)\n","            error_fig = vhr.plot.visualize_BPM_Errors_heatmap(image, ldmks, timesES, wind, timesGT_ECG, bpmGT_ECG, patch_shape, overlap, vmin=-20, vmax=20)\n","            \n","            # Construct the filenames\n","            estimated_filename = os.path.join(path, f\"{method}_{camera}_estimated\", f\"{wind+1}.png\")\n","            error_filename = os.path.join(path, f\"{method}_{camera}_error\", f\"{wind+1}.png\")\n","            \n","            # Save the figures using cv2.imwrite\n","            cv2.imwrite(estimated_filename, estimated_fig)\n","            cv2.imwrite(error_filename, error_fig)\n","\n","        # Get BPM\n","\n","        hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)\n","        if method == \"PCA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","        if method == \"ICA\":\n","            hol_bpmES = [x[0] for x in hol_bpmES]\n","\n","        patch_bpmES = vhr.BPM.BVP_to_BPM_cuda(patch_bvps, fps)\n","        patch_median_bpmES, MAD = vhr.BPM.BPM_median(patch_bpmES)\n","        ma = vhr.extraction.MotionAnalysis(sig_extractor, wsize, fps)\n","        psd_bpmES = vhr.BPM.BPM_clustering(ma, patch_bvps, fps, wsize, movement_thrs=None, opt_factor=0.5)\n","            \n","        # Get the errors\n","\n","        # Holistic errors\n","        if sigGT_ECG is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","        elif sigGT_ABP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ABP, timesES, timesGT_ABP)\n","        elif sigGT_CVP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_CVP, timesES, timesGT_CVP)\n","\n","        # Update the DataFrame\n","        ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","        OUTPUT = [timesES, hol_bpmES, ERRORS]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'HOL_' + method + '_' + camera] = OUTPUT\n","\n","        # Patch errors\n","        # Medians\n","        if sigGT_ECG is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, patch_median_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","        elif sigGT_ABP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, patch_median_bpmES, bpmGT_ABP, timesES, timesGT_ABP)\n","        elif sigGT_CVP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, patch_median_bpmES, bpmGT_CVP, timesES, timesGT_CVP)\n","\n","        # Update the DataFrame\n","        ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","        OUTPUT = [timesES, patch_median_bpmES, ERRORS]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'PATCH_' + method + '_MED_' + camera] = OUTPUT\n","\n","        # PSD Clustering\n","        if sigGT_ECG is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, psd_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","        elif sigGT_ABP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, psd_bpmES, bpmGT_ABP, timesES, timesGT_ABP)\n","        elif sigGT_CVP is not None:\n","            RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, psd_bpmES, bpmGT_CVP, timesES, timesGT_CVP)\n","\n","        # Update the DataFrame\n","        ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","        OUTPUT = [timesES, psd_bpmES, ERRORS]\n","        df.at[df[df['INSTANCE'] == int(instance)].index[0], 'PATCH_' + method + '_PSD_' + camera] = OUTPUT\n"]},{"cell_type":"markdown","metadata":{},"source":["## Run the function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test the function\n","process_video(df,1,'K1')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_name = 'CVP'\n","window_info = [8,1]     # window size and stride\n","seconds = 0     # seconds of video to be processed (0 for all video)\n","skin_threshold = 30    # threshold for skin extraction\n","pixel_thresholds = [5,230] #low and high thresholding\n","frequency_bandpass = [0.65,4.0] # bandpass range\n","patch_info = [40,0] # size, pixel overlap\n","\n","df = load_or_create_dataframe(results_path)\n","methods = ['CHROM', 'LGI', 'POS', 'PBV', 'GREEN', 'OMIT','ICA','PCA']\n","\n","def process_cvp_video(df,instance,camera,methods,pixel_threshold=30,wsize=8,seconds=0):\n","    \n","    # Set the parameters\n","    dataset, sig_extractor = initialize_objects(df,instance,camera)\n","    \n","    # Read the ground truth\n","    read_ground_truth_data(df,instance,camera,dataset)\n","\n","    # Holistic Processing\n","    df, sig_extractor = holistic_processing(df,instance,camera,sig_extractor,wsize,pixel_threshold)\n","    \n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_name = 'CVP'\n","window_info = [8,1]     # window size and stride\n","seconds = 0     # seconds of video to be processed (0 for all video)\n","skin_threshold = 30    # threshold for skin extraction\n","pixel_thresholds = [5,230] #low and high thresholding\n","frequency_bandpass = [0.65,4.0] # bandpass range\n","df = load_or_create_dataframe(results_path)\n","methods = ['CHROM', 'LGI', 'POS', 'PBV', 'GREEN', 'OMIT','ICA','PCA']\n","instance = 1\n","camera = \"K1\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df, dataset, sig_extractor = initialize_objects(df,instance,camera)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = read_ground_truth_data(df,instance,camera,dataset,window_info)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["OVvq-D_A2eSQ","TXFwg6twximv","jOASmqeq6HI-","-Z_tKTqNkPaA","Nl0sOh5zOBRl","lthrNMLnGwoE"],"private_outputs":true,"provenance":[{"file_id":"1p-hc4NQyETx-07V7sbvgVOdiiaJzJWCn","timestamp":1673623253938},{"file_id":"1MUMqVpQ1xx6XwS1G4iTHU7lbdMVbHGBJ","timestamp":1640772983263}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
