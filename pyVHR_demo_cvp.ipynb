{"cells":[{"cell_type":"markdown","metadata":{"id":"RndCVqh915_g"},"source":["---\n","# **PyVHR using the CVP Dataset**\n","---"]},{"cell_type":"markdown","metadata":{},"source":["# Single Video Test"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFP37oIXuKQN"},"outputs":[],"source":["# -- MAIN IMPORT\n","\n","import pyVHR as vhr\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from pyVHR.utils.errors import *\n","from pyVHR.BVP import *\n","\n","# Plotting: set 'colab' for Google Colaboratory, 'notebook' otherwise\n","vhr.plot.VisualizeParams.renderer = 'notebook'"]},{"cell_type":"markdown","metadata":{"id":"4cvCF5ktaWIH"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYKTCUkf7Y6l"},"outputs":[],"source":["# -- LOAD A DATASET\n","\n","dataset_name = 'CVP'                      # the name of the python class handling it \n","\n","video_DIR = \"C:\\\\Users\\\\20759193\\\\source\\\\repos\\\\pyVHR\\\\data\"  # dir containing videos\n","BVP_DIR = \"C:\\\\Users\\\\20759193\\\\source\\\\repos\\\\pyVHR\\\\data\"    # dir containing the ground truth signals\n","\n","dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n","allvideo = dataset.videoFilenames\n","allsignals = dataset.sigFilenames\n","\"\"\"\n","# print the first 10 in the list of video names with the progressive index (idx)\n","for v in range(len(allvideo)):\n","  while v < 5:\n","    print(v, allvideo[v])\n","    break\n","\n","# print the first 10 in the list of ground truths with the progressive index (idx)\n","for s in range(len(allsignals)):\n","  while s < 5: \n","    print(s, allsignals[s])\n","    break\n","  \"\"\""]},{"cell_type":"markdown","metadata":{},"source":["## Load the Ground Truth Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKz1w2i48u-Z"},"outputs":[],"source":["# -- PARAMETER SETTING\n","wsize = 8        # seconds of video processed (with overlapping) for each estimate \n","video_idx = 4 #np.random.randint(0,len(allvideo))    # index of the video to be processed\n","fname = dataset.getSigFilename(video_idx) # get the filename of the signal file\n","videoFileName = dataset.getVideoFilename(video_idx) # get the filename of the video file\n","\n","try:\n","    sigGT_ECG = dataset.readSigfile(fname, signalGT='ECG')\n","    sigGT_ECG.show_ECG = True\n","    bpmGT_ECG, timesGT_ECG = sigGT_ECG.getBPM(wsize)\n","except Exception as e:\n","    print(\"ECG not found. Error:\", e)\n","    sigGT_ECG = bpmGT_ECG = timesGT_ECG = None\n","\n","try:\n","    sigGT_ABP = dataset.readSigfile(fname, signalGT='ABP')\n","    bpmGT_ABP, timesGT_ABP = sigGT_ABP.getBPM(wsize)\n","except Exception as e:\n","    print(\"ABP not found. Error:\", e)\n","    sigGT_ABP = bpmGT_ABP = timesGT_ABP = None\n","\n","try:\n","    sigGT_CVP = dataset.readSigfile(fname, signalGT='CVP')\n","    bpmGT_CVP, timesGT_CVP = sigGT_CVP.getBPM(wsize)\n","except Exception as e:\n","    print(\"CVP not found. Error:\", e)\n","    sigGT_CVP = bpmGT_CVP = timesGT_CVP = None\n","\n","\n","\n","path_segments = videoFileName.split(\"\\\\\")\n","instance, camera = path_segments[-2].split(\"_\")\n","\n","print('Video processed name: ', videoFileName)\n","print('Signal processed name: ', fname)\n","print('Instance:            ', instance)\n","print('Camera:              ', camera)\n","fps = vhr.extraction.get_fps(videoFileName)\n","print('Video frame rate:     ',fps)\n","\n","# -- DISPLAY CVP_GT SPECTROGRAM\n","try:\n","    print(\"CVP Spectrum\")\n","    sigGT_CVP.displaySpectrum()\n","except Exception as e:\n","    print(\"No CVP\")\n","\n","try:\n","    print(\"ABP Spectrum\")\n","    sigGT_ABP.displaySpectrum()\n","except Exception as e:\n","    print(\"No ABP\")\n","\n","try:\n","    print(\"ECG BPMs\")\n","    for t in range(len(timesGT_ECG)):\n","        print(round(timesGT_ECG[t],2), round(bpmGT_ECG[t],2))\n","except Exception as e:\n","    print(\"No ECG\")\n","\n","# -- DISPLAY VIDEO FRAMES\n","\n","vhr.plot.display_video(videoFileName)"]},{"cell_type":"markdown","metadata":{"id":"OVvq-D_A2eSQ"},"source":["# Skin extraction\n","\n","We've defined a custom version of skin extraction for the neck, compared with the face detection versions that use the **convex hull** or **face parsing** versions.\n","\n","Once the skin is selected, select how to process it: \n","\n","* **Patches**: small facial regions of skin  centered on landmarks (provides multiple estimators)\n","* **Holistic**: convex hull of patches or face parsing CNN (provides a single  estimator)\n","\n","***Note***: `SignalProcessing` is powered by CUDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NE9MUZm2jWa"},"outputs":[],"source":["sig_extractor = vhr.extraction.SignalProcessing()\n","sig_extractor.display_cuda_device()\n","sig_extractor.choose_cuda_device(0)"]},{"cell_type":"markdown","metadata":{"id":"VA8WkKVSaqrh"},"source":["Use our custom skin extraction method where we define a rectangle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvtkPciialFx"},"outputs":[],"source":["sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU'))"]},{"cell_type":"markdown","metadata":{"id":"DJNvz6Jqehkj"},"source":["Choose a specific number of frames of the video to process... "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nsze-ygegTB"},"outputs":[],"source":["# set the number of seconds (0 for all video)\n","seconds = 0\n","sig_extractor.set_total_frames(seconds*fps)"]},{"cell_type":"markdown","metadata":{"id":"m4uYGtL-oYrS"},"source":["### Color-thresholding\n","\n","**OPTIONAL**: Both signal extraction and skin extraction have a color-threshold filter for removing unwanted RGB colors. We can set the RGB threshold interval using theese classes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9q9kmRioXtW"},"outputs":[],"source":["vhr.extraction.SkinProcessingParams.RGB_LOW_TH =  0\n","vhr.extraction.SkinProcessingParams.RGB_HIGH_TH = 255\n","\n","vhr.extraction.SignalProcessingParams.RGB_LOW_TH = 0\n","vhr.extraction.SignalProcessingParams.RGB_HIGH_TH = 255"]},{"cell_type":"markdown","metadata":{"id":"cYjkNk5dp8D5"},"source":["## Visualize skin and landmarks \n","\n","* To visualize skin processing intermediate results call `set_visualize_skin_and_landmarks` method.\n","* To retrieve any intermediate result call the methods `get_visualize_skin` and \n","`get_visualize_patches`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyq4D--Pqmey"},"outputs":[],"source":["# -- SET VISUALIZATION MODE \n","sig_extractor.set_visualize_skin_and_landmarks(\n","      visualize_skin=True, \n","      visualize_landmarks=True, \n","      visualize_landmarks_number=True, \n","      visualize_patch=True)"]},{"cell_type":"markdown","metadata":{"id":"TXFwg6twximv"},"source":["# ROI processing and RGB computation\n","\n","Choose how to extract the RGB signal from ROI:\n","\n","* **Holistic** mean\n","* **Patches** mean\n","\n","Patches are square (with a fixed edge for all) or rectangular (with xy_dimension for each region)."]},{"cell_type":"markdown","metadata":{"id":"jOASmqeq6HI-"},"source":["# Holistic extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXcR6pc49HL_"},"outputs":[],"source":["# -- HOLISTIC EXTRACTION\n","hol_sig = sig_extractor.extract_holistic_rectangle(videoFileName,40)\n","print('Size: (#frames, #landmarks, #channels) = ',hol_sig.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AE04zo6Xf2xl"},"outputs":[],"source":["# -- INTERACTIVE VISUALIZATION OF EXTRACTED SKIN\n","visualize_skin_coll = sig_extractor.get_visualize_skin()\n","print('Number of frames processed: ',len(visualize_skin_coll))\n","vhr.plot.interactive_image_plot(visualize_skin_coll,1.0)"]},{"cell_type":"markdown","metadata":{"id":"6fnzk_QEyH9L"},"source":["## Signal windowing\n","\n","Windowing means to split a video into a set of strided and overlapped windows of frames. For each window the RGB signal is estracted by averaging over pixels in holistic (all skin pixels) or local (averaging on patches) fashion. Shapes are `(rgb_channels, #frames)` and `(#landmarks, rgb_channels, #frames)` respectively. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYi_G8rzgfHB"},"outputs":[],"source":["# -- WINDOWING OF RGB SIGNALS (HOLISTIC)\n","windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps)\n","print('Num windows: ',len(windowed_hol_sig))\n","print('Num channels and window length: ', windowed_hol_sig[0].shape)\n","\n","\"\"\"\n","# -- PLOT A WINDOW (randomly chosen)\n","w = np.random.randint(0, len(windowed_hol_sig))   # window number\n","vhr.plot.visualize_windowed_sig(windowed_hol_sig, w)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"-Z_tKTqNkPaA"},"source":["## Pre-filtering\n","\n","The implemented (standard) filters are:\n","\n","* `rgb_filter_ths`: color threshold filter that filters out signals that, in at least one frame of the window, are outside the rgb colors interval `[(LOW, LOW, LOW), (HIGH, HIGH, HIGH)]` where `LOW` is the dictionary parameter `RGB_LOW_TH`, and `HIGH` is `RGB_HIGH_TH` (we suggest to always use this filter before applying a BVP method)\n","* `detrend`: apply detrend to the signal\n","* `sg_detrend`: apply detrend to the signal, i.e. remove the low-frequency components with the low-pass filter developed by Savitzky-Golay\n","* `zscore`: apply z-score to the signal\n","* `BPfilter`: apply Butterworth band-pass filter to the signal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47GUg8tvvEz2"},"outputs":[],"source":["# -- APPLY TRESHOLDING ON RGB COLORS (suggested)\n","\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': vhr.extraction.SignalProcessingParams.RGB_LOW_TH, 'RGB_HIGH_TH': vhr.extraction.SignalProcessingParams.RGB_HIGH_TH})\n","\n","print('Num windows: ', len(filtered_windowed_hol_sig))\n","print('Win size: (#signals, #channels, #frames) = ', filtered_windowed_hol_sig[0].shape)\n","\n","# -- SELECT THE FILTER CASCADE\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})\n","#filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.detrend)\n","#filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.sg_detrend)\n","#filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.zscore)\n","#filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.zeromean)\n","print('Num windows: ', len(filtered_windowed_hol_sig))\n","print('Win size: (#signals, #channels, #frames) = ', filtered_windowed_hol_sig[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"72zO3M0wDOrQ"},"source":["## Method: BVP extraction\n","\n","To extract the BVP signal call the function `RGB_sig_to_BVP` with the following parameters:\n","\n","\n","*   `filt_windowed_sig`: the list of windows\n","*   `fps`: frame rate\n","*   `device_type`: `cuda`, `cpu`, `torch`\n","*   `method`: method function that supports method_type device\n","*   `params`: dictionary of parameters needed by the method ( default is {}).\n","\n","Core methods implemented within pyVHR:\n","* **Methods**: `cpu_CHROM`, `cupy_CHROM`, `torch_CHROM`, `cpu_LGI`, `cpu_POS`, `cupy_POS`, `cpu_PBV`, `cpu_PCA`, `cpu_GREEN`, `cpu_OMIT`, `cpu_ICA`, `cpu_SSR`\n","\n","\n","***Note***: pyVHR contains many methods, but you can also use a custom method. Remember that it must accept a numpy.ndarray with shape (num_estimators, channels, num_frames) and return a numpy.ndarray with shape (num_estimators, num_frames)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrkIidXEIH9P"},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","w = np.random.randint(0, len(windowed_hol_sig))  # window number\n","vhr.plot.visualize_windowed_sig(filtered_windowed_hol_sig, w)\"\"\""]},{"cell_type":"markdown","metadata":{"id":"2OvQ8Au_1eLL"},"source":["*bvps* is a list of length num_windows of numpy.ndarray with shape (num_estimators,num_frames)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sySCrAinghKt","scrolled":true},"outputs":[],"source":["# -- APPLY A METHOD TO EXTRACT BVP\n","\n","\n","\n","\n","# CHROM\n","#hol_bvps = RGB_sig_to_BVP(windowed_hol_sig, fps, device_type='cpu', method=cpu_CHROM)\n","#hol_bvps = RGB_sig_to_BVP(windowed_hol_sig, fps, device_type='torch', method=torch_CHROM)\n","hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","\n","# LGI\n","#bvp = hol_bvps.append(RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI))\n","#print(\"LGI: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# POS\n","#hol_bvps = RGB_sig_to_BVP(windowed_hol_sig, fps, device_type='cpu', method=cpu_POS, params={'fps':fps})\n","#bvp = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","#print(\"POS: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# PBV\n","#bvp = hol_bvps.append(RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV))\n","#print(\"PBV: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# PCA\n","#hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","#print(\"PCA: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# GREEN\n","#bvp = hol_bvps.append(RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN))\n","#print(\"GREEN: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# OMIT\n","#bvp = hol_bvps.append(RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT))\n","#print(\"OMIT: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# ICA\n","#hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","#print(\"ICA: \", bvp[0].shape)\n","#hol_bvps.append(bvp)\n","\n","# SSR\n","#hol_bvps.append(RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_SSR, params={'fps':fps}))\n","\n","#print('Number of windows: ', len(hol_bvps))\n","#print('Number of estimators and number of number of frames in a windows: ', hol_bvps[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_lZaw95mBtA"},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","\n","w = np.random.randint(0, len(filtered_windowed_hol_sig))  # window number\n","vhr.plot.visualize_BVPs(hol_bvps, w)\"\"\""]},{"cell_type":"markdown","metadata":{"id":"O2abphyGZjbA"},"source":["## Post Filtering\n","\n","As with prefiltering, we can apply all the filters showed before also to the *BVP*. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ovv6a1hTZlfr"},"outputs":[],"source":["# -- APPLY BPFILTER TO BVP WINDOWED \n","\n","hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':0.75,'maxHz':4.0,'fps':fps})\n","\n","#print('Num windows: ', len(hol_bvps))"]},{"cell_type":"markdown","metadata":{"id":"Nl0sOh5zOBRl"},"source":["## BVP spectrum\n","\n","BVP spectrum analysis via PSD for holistic and patches approaches."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpZ4EvdcOmfi"},"outputs":[],"source":["\"\"\"w = np.random.randint(0, len(windowed_hol_sig))  # window number\n","vhr.plot.visualize_BVPs_PSD(hol_bvps, w, fps)\"\"\""]},{"cell_type":"markdown","metadata":{"id":"2kGmDLaA1BxR"},"source":["## BMP estimation \n","\n","This function process all the windows and all the estimators (one for holistic and many for patches), and returns a list of numpy ndarray with shape (num_estimators,)."]},{"cell_type":"markdown","metadata":{"id":"OSg5KALx2xpH"},"source":["## BPM vs GT ANALYSIS\n","\n","Error computation and visualization "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IT5Q0v7qgjrh"},"outputs":[],"source":["# -- BPM ESTIMATION \n","\n","#hol_bpmES = vhr.BPM.BVP_to_BPM(hol_bvps, fps)       # CPU version\n","\n","hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)  # CUDA version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfvIniEcHBBs"},"outputs":[],"source":["# -- PRINT ERRORS USING METRICS: RMSE, MAE, MAX, PCC, CCC, SNR\n","# Get errors RMSE, MAE, MAX, PCC, CCC, SNR\n","RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","#printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","#displayErrors(hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"markdown","metadata":{},"source":["# Patch Extraction"]},{"cell_type":"markdown","metadata":{},"source":["## Get the patch_sig"]},{"cell_type":"markdown","metadata":{},"source":["### Defining fixed landmarks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Given the size of the video, we set our shape of each patch, and how much overlap we want for the signals, to define\n","# the landmarks (think coordinates) of the patches.\n","sig_extractor.set_square_patches_side(50.)\n","sig_extractor.set_fixed_patches(videoFileName,region_type=\"squares\",overlap=0)\n","print(\"Number of patches is: \", len(sig_extractor.ldmks))\n","wind = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sig_extraction_method = \"mean\" # or \"median\"\n","sig_extractor.thickness = 1\n","sig_extractor.font_size = 0.1\n","patch_sig = sig_extractor.extract_fixed_patches(sig_extraction_method,segmented_frames = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -- INTERACTIVE VISUALIZATION OF PATCHES\n","visualize_patches_coll = sig_extractor.get_visualize_patches()\n","print('Number of frames processed: ',len(visualize_patches_coll))\n","vhr.plot.interactive_image_plot(visualize_patches_coll)"]},{"cell_type":"markdown","metadata":{},"source":["## Signal Windowing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GMFO4IM_YGm"},"outputs":[],"source":["# -- WINDOWING OF RGB SIGNALS ON PATCHES \n","windowed_patch_sig, timesES = vhr.extraction.sig_windowing(patch_sig, wsize, 1, fps)\n","print('Num windows: ',len(windowed_patch_sig))\n","print('Num patches, Num channels, and window length: ', windowed_patch_sig[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeyvKWW8_YGn","scrolled":true},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","w = np.random.randint(0, len(windowed_patch_sig))  # window number\n","vhr.plot.visualize_windowed_sig(windowed_patch_sig, w)\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["## Filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izOdRE6dse5Q"},"outputs":[],"source":["# -- APPLY TRESHOLDING ON RGB COLORS (suggested)\n","wind = 0\n","filtered_windowed_patch_sig, patch_ids = vhr.BVP.apply_custom_filter(windowed_patch_sig, vhr.BVP.rgb_filter_th_with_ids, params={'RGB_LOW_TH': vhr.extraction.SignalProcessingParams.RGB_LOW_TH, 'RGB_HIGH_TH': vhr.extraction.SignalProcessingParams.RGB_HIGH_TH})\n","print('Num windows: ', len(filtered_windowed_patch_sig))\n","print('Win size: (#landmarks, #channels, #frames) = ', filtered_windowed_patch_sig[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["patch_ids[wind].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STAe3r7lFktH"},"outputs":[],"source":["# -- SELECT THE FILTER CASCADE\n","\n","filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.75,'maxHz':4.0,'fps':fps})\n","#filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.sg_detrend)\n","#filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.detrend, params={'detLambda':100}) \n","#filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.zscore)\n","#filtered_windowed_patch_sig = vhr.BVP.apply_filter(filtered_windowed_patch_sig, vhr.BVP.zeromean)\n","print('Num windows: ', len(filtered_windowed_patch_sig))\n","print('Win size: (#landmarks, #channels, #frames) = ', filtered_windowed_patch_sig[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRsqqG9dH4BE"},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","\n","w = np.random.randint(0, len(windowed_patch_sig))  # window number\n","vhr.plot.visualize_windowed_sig(filtered_windowed_patch_sig, w)\"\"\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## BVP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lABT_DrHDfVr","scrolled":true},"outputs":[],"source":["# -- APPLY A METHOD TO EXTRACT BVP\n","\n","from pyVHR.BVP import *\n","\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_CHROM)\n","patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_CHROM)\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='torch', method=torch_CHROM)\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_POS, params={'fps':fps})\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_LGI)\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_GREEN)\n","#patch_bvps = RGB_sig_to_BVP(filtered_windowed_patch_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'second_comp'})\n","\n","print('Number of windows: ', len(patch_bvps))\n","print('Number of estimators and number of number of frames in a windows: ', patch_bvps[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtvJWZqgDfVr"},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","w = np.random.randint(0, len(windowed_patch_sig))  # window number\n","vhr.plot.visualize_BVPs(patch_bvps, w)\"\"\"\n","\n","\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","wind = np.random.randint(0, len(windowed_hol_sig))  # window number\n","vhr.plot.visualize_BVPs(hol_bvps, wind)\"\"\""]},{"cell_type":"markdown","metadata":{"id":"DDcy6Y4zF0-g"},"source":["## Filter BVP\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYpLwScIDfVr"},"outputs":[],"source":["# -- APPLY BPFILTER TO BVP WINDOWED PATCHES\n","\n","patch_bvps = vhr.BVP.apply_filter(patch_bvps, BPfilter, params={'order':6,'minHz':0.75,'maxHz':4.0,'fps':fps})\n","print('Num windows: ', len(patch_bvps))\n","print('Win size: (#landmarks, #frames) = ', patch_bvps[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["processed_patch_bvps = vhr.plot.visualize.process_patch_BVPs(sig_extractor.fixed_patches, patch_ids, patch_bvps, fps, minHz = 0.65, maxHz = 4.0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Win size: (#landmarks, #frames) = ', patch_bvps[wind].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9dIB17SDfVr"},"outputs":[],"source":["\"\"\"# -- PLOT A WINDOW (randomly chosen)\n","\n","w = np.random.randint(0, len(windowed_patch_sig))  # window number\n","vhr.plot.visualize_BVPs(patch_bvps, w)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pty64CpG0rb"},"outputs":[],"source":["#wind = np.random.randint(0,len(patch_bvps))  # window number\n","#vhr.plot.visualize_BVPs_PSD_with_IDs(patch_bvps,patch_ids, wind, fps, maxHz=10)"]},{"cell_type":"markdown","metadata":{"id":"4WMWwvD0lU0o"},"source":["### BPM by median"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdJu8gZRfwxn"},"outputs":[],"source":["# -- BPM ESTIMATION BY PATCHES\n","#patch_bpmES = vhr.BPM.BVP_to_BPM(patch_bvps, fps)          # CPU version\n","\n","patch_bpmES = vhr.BPM.BVP_to_BPM_cuda(patch_bvps, fps)    # CUDA version"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def add_fixed_patch_info(fixed_patches,patch_ids,patch_bvps,patch_bpmES,timesES):\n","    for fixed_patch in fixed_patches:\n","        for window in range(len(patch_ids)):\n","            # loop through each patch, check if it's the one we're after, and append if it is, including the \n","            for patch in range(len(patch_ids[window])):\n","                if patch_ids[window][patch] == fixed_patch.ID:\n","                    fixed_patch.times.append(timesES[window])\n","                    fixed_patch.bvps.append(np.array([patch_bvps[window][patch]]))\n","                    fixed_patch.bpms.append(np.array(patch_bpmES[window][patch]))\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_snrs(fixed_patches,gt_bpms,fps):\n","    for fixed_patch in fixed_patches:\n","        if len(fixed_patch.times) > 0:\n","            fixed_patch.snr = []\n","            for i, bvp in enumerate(fixed_patch.bvps):\n","                fixed_patch.snr.append(get_SNR([bvp],fps,gt_bpms,[fixed_patch.times[i]]))\n","            fixed_patch.snr = np.array(fixed_patch.snr)\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_errors(fixed_patches,gt_times,gt_bpms):\n","    for fixed_patch in fixed_patches:\n","        if len(fixed_patch.times) > 0:\n","            temp_bpms = np.expand_dims(np.array(fixed_patch.bpms),axis=0)\n","            fixed_patch.rmse = RMSEerror(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","            fixed_patch.mae = MAEerror(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","            fixed_patch.max = MAXError(temp_bpms,gt_bpms,fixed_patch.times,gt_times)\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_patch_metrics(fixed_patches,gt_times,gt_bpms,fps):\n","    fixed_patches = update_patch_snrs(fixed_patches,gt_bpms,fps)\n","    fixed_patches = update_patch_errors(fixed_patches,gt_times,gt_bpms)\n","    return fixed_patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sig_extractor.fixed_patches = add_fixed_patch_info(sig_extractor.fixed_patches,patch_ids,patch_bvps,patch_bpmES,timesES)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sig_extractor.fixed_patches = update_patch_metrics(sig_extractor.fixed_patches,timesGT_ECG,bpmGT_ECG,fps)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read a json dataframe\n","df = pd.read_json(\"C:\\\\Users\\\\20759193\\\\source\\\\repos\\\\pyVHR\\\\results\\\\patch_dataframes\\\\2\\\\CHROM_K1_patch_df.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_patch_dataframe(fixed_patches):    \n","    patch_data = []\n","    for fixed_patch in fixed_patches:\n","        patch_data.append([fixed_patch.ID,\n","                        fixed_patch.x_min,\n","                        fixed_patch.x_max,\n","                        fixed_patch.y_min,\n","                        fixed_patch.y_max,\n","                        np.array(fixed_patch.times),\n","                        np.array(fixed_patch.bvps),\n","                        np.array(fixed_patch.bpms),\n","                        fixed_patch.rmse[0],\n","                        fixed_patch.mae[0],\n","                        fixed_patch.max[0],\n","                        np.array(fixed_patch.snr)])\n","    df = pd.DataFrame(patch_data,columns = [\"ID\",\"x_min\",\"x_max\",\"y_min\",\"y_max\",\"times\",\"bvps\",\"bpms\",\"RMSE\",\"MAE\",\"MAX\",\"SNRs\"])\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["patch_df = make_patch_dataframe(sig_extractor.fixed_patches)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -- MEDIANS OF BPMS\n","\n","patch_median_bpmES, MAD = vhr.BPM.BPM_median(patch_bpmES)\n","\n","# -- VISUALIZE ALL BPMs AND MEDIANS\n","vhr.plot.visualize_multi_est_BPM_vs_BPMs_list([patch_bpmES, timesES], [[patch_median_bpmES, timesES, \"medianES\"],[bpmGT_ECG, timesGT_ECG, \"GT\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["patch_shape = (int(sig_extractor.square),int(sig_extractor.square))\n","patch_overlap = sig_extractor.overlap\n","image = sig_extractor.display_frame\n","overlap = sig_extractor.overlap\n","estimated_figs = []\n","error_figs = []\n","\n","for wind in range(len(patch_bvps)):\n","    ldmks, fig1 = vhr.plot.visualize_BVPs_heatmap(image, patch_bvps, patch_ids, wind, patch_shape, overlap, fps, minHz=0.65, maxHz=4)\n","    fig2 = vhr.plot.visualize_BPM_Errors_heatmap(image, ldmks, timesES, wind, timesGT_ECG, bpmGT_ECG, patch_shape, overlap,vmin=-20,vmax=20)\n","    estimated_figs.append(fig1)\n","    error_figs.append(fig2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vhr.plot.interactive_image_plot(estimated_figs,1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vhr.plot.interactive_image_plot(error_figs,1.0)"]},{"cell_type":"markdown","metadata":{"id":"nw4eCc7QHCwN"},"source":["### Patches - medians\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU1Hg6E9gngX"},"outputs":[],"source":["# -- PRINT ERRORS USING METRICS: RMSE, MAE, MAX, PCC, CCC, SNR\n","\n","from pyVHR.utils.errors import getErrors, printErrors, displayErrors\n","\n","\n","RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, patch_median_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(patch_median_bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"markdown","metadata":{"id":"-Rw9CX-NGQCs"},"source":["## BPM by PSD\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlWDlTPPDfVt"},"outputs":[],"source":["# -- BPM ESTIMATION BY PSD CUMUL\n","ma = vhr.extraction.MotionAnalysis(sig_extractor, wsize, fps)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["psd_bpmES = vhr.BPM.BPM_clustering(ma, patch_bvps, fps, wsize, movement_thrs=None, opt_factor=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# -- PRINT ERRORS USING METRICS: RMSE, MAE, MAX, PCC, SNR\n","from pyVHR.utils.errors import getErrors, printErrors, displayErrors\n","\n","RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(patch_bvps, fps, psd_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(psd_bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"markdown","metadata":{},"source":["# Deep Models - Holistic"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyVHR.utils.errors import getErrors, printErrors, displayErrors, BVP_windowing\n","frames = sig_extractor.extract_raw(videoFileName)\n","skin_frames = np.array(sig_extractor.visualize_skin_collection)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# apply MTTS_CAN model\n","bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(frames, fps, verb=1)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps) \n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for patch in sig_extractor.fixed_patches:\n","    bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(patch.raw_frames, fps, verb=0)\n","    bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    patch.bvps = bvp_win\n","    patch.bpms = bpmES\n","    patch.times = timesES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# apply MTTS_CAN model\n","bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(skin_frames, fps, verb=1)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps) \n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# apply HR_CNN model\n","bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(frames)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)\n","\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps) \n","\n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# apply HR_CNN model\n","bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(skin_frames)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)\n","\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps) \n","\n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT_ECG, timesES, timesGT_ECG)"]},{"cell_type":"markdown","metadata":{},"source":["## Deep Processing - Patches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for patch in tqdm(sig_extractor.fixed_patches):\n","    patch.bvps = []\n","    patch.bpms = []\n","    patch.times = []\n","    patch.snr = []\n","    patch.rmse = []\n","    patch.mae = []\n","    patch.max = []\n","    # apply MTTS_CAN model\n","    bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(patch.raw_frames)\n","    bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","    # BVP windowing & BPM estimate\n","    bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","    bpmES = vhr.BPM.BVP_to_BPM_cuda(bvp_win, fps)\n","    patch.bvps = bvp_win\n","    patch.bpms = bpmES\n","    patch.times = timesES\n","    # compute and print errors\n","    RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","    patch.rmse = RMSE\n","    patch.mae = MAE\n","    patch.max = MAX\n","    patch.snr = SNR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sig_extractor.fixed_patches[0].snr"]},{"cell_type":"markdown","metadata":{},"source":["## Process the whole dataset"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"# Single Block Patches\n","\n","# Initialise everything\n","path = df.loc[df['INSTANCE'] == instance, camera + '_DATA_PATH'].values[0]\n","videoFileName = path + camera + \"_Cropped_Colour.mkv\"\n","sigFileName = path + \"data.csv\"\n","sig_extractor = vhr.extraction.SignalProcessing()   # Set the class\n","sig_extractor.set_visualize_skin_and_landmarks(\n","    visualize_skin=True, \n","    visualize_landmarks=True, \n","    visualize_landmarks_number=True, \n","    visualize_patch=True)\n","sig_extractor.choose_cuda_device(0)                 # Set the GPU\n","sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU')) # Set the skin extractor\n","sig_extractor.set_total_frames(seconds*fps) # Set the number of frames\n","pixel_threshold = 30\n","\n","# Get the ground truth data\n","try:\n","    sigGT_ECG = dataset.readSigfile(fname, signalGT='ECG')\n","    sigGT_ECG.show_ECG = True\n","    bpmGT_ECG, timesGT_ECG = sigGT_ECG.getBPM(wsize)\n","    # Add these to the DataFrame\n","    ecg_bpms = bpmGT_ECG.tolist()\n","    ecg_times = timesGT_ECG.tolist()\n","    ECG = [ecg_times, ecg_bpms]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'ECG'] = ECG\n","except Exception as e:\n","    print(\"ECG not found. Error:\", e)\n","    sigGT_ECG = bpmGT_ECG = timesGT_ECG = None\n","\n","try:\n","    sigGT_ABP = dataset.readSigfile(fname, signalGT='ABP')\n","    bpmGT_ABP, timesGT_ABP = sigGT_ABP.getBPM(wsize)\n","    # Add these to the DataFrame\n","    abp_bpms = bpmGT_ABP.tolist()\n","    abp_times = timesGT_ABP.tolist()\n","    ABP = [abp_times, abp_bpms]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'ABP'] = ABP\n","except Exception as e:\n","    print(\"ABP not found. Error:\", e)\n","    sigGT_ABP = bpmGT_ABP = timesGT_ABP = None\n","\n","try:\n","    sigGT_CVP = dataset.readSigfile(fname, signalGT='CVP')\n","    bpmGT_CVP, timesGT_CVP = sigGT_CVP.getBPM(wsize)\n","    # Add these to the DataFrame\n","    cvp_bpms = bpmGT_CVP.tolist()\n","    cvp_times = timesGT_CVP.tolist()\n","    CVP = [cvp_times, cvp_bpms]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'CVP'] = CVP\n","except Exception as e:\n","    print(\"CVP not found. Error:\", e)\n","    sigGT_CVP = bpmGT_CVP = timesGT_CVP = None\n","\n","# Prefilter before we use the specific method\n","hol_sig = sig_extractor.extract_holistic_rectangle(videoFileName,pixel_threshold)    # Extract the signal\n","# TODO: Add patch signal\n","\n","# Save the 10th frame just to check filtering.\n","frames = sig_extractor.extract_raw(videoFileName)\n","print(frames.shape)\n","skin_frames = np.array(sig_extractor.visualize_skin_collection)\n","print(skin_frames.shape)\n","# TODO: Add patch frames\n","\n","cv2.imwrite(path + 'frame.png', cv2.cvtColor(frames[9], cv2.COLOR_RGB2BGR))\n","cv2.imwrite(path + 'skin_frame.png', cv2.cvtColor(skin_frames[9], cv2.COLOR_RGB2BGR))\n","\n","\n","windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps) # Window the signal\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': 5, 'RGB_HIGH_TH': 230}) # Apply the threshold filter\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps}) # Apply the other filter\n","\n","# TODO: add the patched version of all of this\n","\n","methods = ['CHROM', 'LGI', 'POS', 'PBV', 'GREEN', 'OMIT','ICA','PCA']\n","for method in methods:\n","    if method == \"CHROM\":\n","        print(\"Processing CHROM - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n","        print(\"PROCESSING CHROM - Patches\")\n","    elif method == \"LGI\":\n","        print(\"PROCESSING LGI - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_LGI)\n","        print(\"Processing LGI - Patches\")\n","    elif method == \"POS\":\n","        print(\"PROCESSING POS - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':fps})\n","        print(\"PROCESSING POS - Patches\")\n","    elif method == \"PBV\":\n","        print(\"PROCESSING PBV - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PBV)\n","        print(\"PROCESSING PBV - Patches\")\n","    elif method == \"PCA\":\n","        print(\"PROCESSING PCA - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'all_comp'})\n","        print(\"PROCESSING PCA - Patches\"\")\n","    elif method == \"GREEN\":\n","        print(\"PROCESSING GREEN - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_GREEN)\n","        print(\"PROCESSING GREEN - Patches\")\n","    elif method == \"OMIT\":\n","        print(\"PROCESSING OMIT - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_OMIT)\n","        print(\"PROCESSING OMIT - Patches\"\")\n","    elif method == \"ICA\":\n","        print(\"PROCESSING ICA - Holistic\")\n","        hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cpu', method=cpu_ICA, params={'component':'all_comp'})\n","        print(\"PROCESSING ICA - Patches\")\n","    else:\n","        print(\"Method not found\")\n","        continue\n","\n","    # Apply the filter            \n","    hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':0.75,'maxHz':4.0,'fps':fps})\n","    # Get BPM\n","\n","    hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)\n","    if method == \"PCA\":\n","        hol_bpmES = [x[0] for x in hol_bpmES]\n","    if method == \"ICA\":\n","        hol_bpmES = [x[0] for x in hol_bpmES]\n","        \n","    # Get the errors\n","    if sigGT_ECG is not None:\n","        RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","    elif sigGT_ABP is not None:\n","        RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ABP, timesES, timesGT_ABP)\n","    elif sigGT_CVP is not None:\n","        RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_CVP, timesES, timesGT_CVP)\n","\n","    # Update the DataFrame\n","    ERRORS = [RMSE, MAE, MAX, PCC, CCC, SNR]\n","    OUTPUT = [timesES, hol_bpmES, ERRORS]\n","    df.at[df[df['INSTANCE'] == int(instance)].index[0], 'HOL_' + method + '_' + camera] = OUTPUT\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"# Single running block\n","\n","# Set our parameters\n","\n","seconds = 0     # seconds of video to be processed (0 for all video)\n","wsize = 8       # seconds of video processed (with overlapping) for each estimate\n","vhr.extraction.SkinProcessingParams.RGB_LOW_TH =  5     # threshold for skin extraction\n","vhr.extraction.SkinProcessingParams.RGB_HIGH_TH = 230   # threshold for skin extraction\n","vhr.extraction.SignalProcessingParams.RGB_LOW_TH = 5    # threshold for signal extraction\n","vhr.extraction.SignalProcessingParams.RGB_HIGH_TH = 230 # threshold for signal extraction\n","sig_extractor.set_visualize_skin_and_landmarks(\n","    visualize_skin=True, \n","    visualize_landmarks=True, \n","    visualize_landmarks_number=True, \n","    visualize_patch=True)\n","\n","# Select the video, to be used in loops later\n","video_idx = 0 #np.random.randint(0,len(allvideo))    # index of the video to be processed\n","\n","# Initialise everything\n","sig_extractor = vhr.extraction.SignalProcessing()   # Set the class\n","sig_extractor.choose_cuda_device(0)                 # Set the GPU\n","sig_extractor.set_skin_extractor(vhr.extraction.SkinExtractionRectangle('GPU')) # Set the skin extractor\n","sig_extractor.set_total_frames(seconds*fps) # Set the number of frames\n","fname = dataset.getSigFilename(video_idx) # get the filename of the signal file\n","videoFileName = dataset.getVideoFilename(video_idx) # get the filename of the video file\n","\n","\n","# Get the ground truth data\n","try:\n","    sigGT_ECG = dataset.readSigfile(fname, signalGT='ECG')\n","    sigGT_ECG.show_ECG = True\n","    bpmGT_ECG, timesGT_ECG = sigGT_ECG.getBPM(wsize)\n","except Exception as e:\n","    print(\"ECG not found. Error:\", e)\n","    sigGT_ECG = bpmGT_ECG = timesGT_ECG = None\n","\n","try:\n","    sigGT_ABP = dataset.readSigfile(fname, signalGT='ABP')\n","    bpmGT_ABP, timesGT_ABP = sigGT_ABP.getBPM(wsize)\n","except Exception as e:\n","    print(\"ABP not found. Error:\", e)\n","    sigGT_ABP = bpmGT_ABP = timesGT_ABP = None\n","\n","try:\n","    sigGT_CVP = dataset.readSigfile(fname, signalGT='CVP')\n","    bpmGT_CVP, timesGT_CVP = sigGT_CVP.getBPM(wsize)\n","except Exception as e:\n","    print(\"CVP not found. Error:\", e)\n","    sigGT_CVP = bpmGT_CVP = timesGT_CVP = None\n","\n","# Prefilter before we use the specific method\n","hol_sig = sig_extractor.extract_holistic_rectangle(videoFileName,40)    # Extract the signal\n","sig_extractor.skin_collection\n","# TODO: Add a save of the 10th frame, normal and segmented\n","windowed_hol_sig, timesES = vhr.extraction.sig_windowing(hol_sig, wsize, 1, fps) # Window the signal\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(windowed_hol_sig, vhr.BVP.rgb_filter_th, fps=fps, params={'RGB_LOW_TH': 5, 'RGB_HIGH_TH': 230}) # Apply the threshold filter\n","filtered_windowed_hol_sig = vhr.BVP.apply_filter(filtered_windowed_hol_sig, vhr.BVP.BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps}) # Apply the other filter\n","# TODO: add the patched version of all of this\n","\n","methods = ['CHROM', 'LGI', 'POS', 'PBV', 'PCA', 'GREEN', 'OMIT', 'ICA']\n","\n","# Use a method to extract the BVP\n","hol_bvps = RGB_sig_to_BVP(filtered_windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM) # Extract the BVP\n","\n","# Apply a filter to the BVP\n","hol_bvps = vhr.BVP.apply_filter(hol_bvps, BPfilter, params={'order':6,'minHz':0.75,'maxHz':4.0,'fps':fps})\n","\n","# Get the BPM\n","hol_bpmES = vhr.BPM.BVP_to_BPM_cuda(hol_bvps, fps)  # CUDA version\n","\n","# Get the errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = getErrors(hol_bvps, fps, hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(hol_bpmES, bpmGT_ECG, timesES, timesGT_ECG)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"for instance in range(len(df['INSTANCE'])):\n","\n","    if df['PROCESSED'][instance] == True:\n","        continue\n","\n","    videoFileNames = []\n","    sigFileNames = []\n","\n","    if df['K1_DATA_PATH'][instance] == None:\n","        continue\n","    videoFileNames.append(df['K1_DATA_PATH'][instance] + \"K1_Cropped_Colour.mkv\")\n","    sigFileNames.append(df['K1_DATA_PATH'][instance] + \"data.csv\")\n","\n","    if df['K2_DATA_PATH'][instance] == None:\n","        continue\n","    videoFileNames.append(df['K1_DATA_PATH'][instance] + \"K1_Cropped_Colour.mkv\")\n","    sigFileNames.append(df['K1_DATA_PATH'][instance] + \"data.csv\")\"\"\""]}],"metadata":{"colab":{"collapsed_sections":["OVvq-D_A2eSQ","TXFwg6twximv","jOASmqeq6HI-","-Z_tKTqNkPaA","Nl0sOh5zOBRl","lthrNMLnGwoE"],"private_outputs":true,"provenance":[{"file_id":"1p-hc4NQyETx-07V7sbvgVOdiiaJzJWCn","timestamp":1673623253938},{"file_id":"1MUMqVpQ1xx6XwS1G4iTHU7lbdMVbHGBJ","timestamp":1640772983263}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
